{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import urllib\n",
        "import json\n",
        "from urllib.parse import urlencode\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import datetime\n",
        "from dateutil.parser import parse\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import random"
      ],
      "metadata": {
        "id": "wTLBkWzKmkBa"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data"
      ],
      "metadata": {
        "id": "vYHPfq1oLI9p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MhY7HFBBLBk4"
      },
      "outputs": [],
      "source": [
        "class Dataset():\n",
        "\n",
        "  def __init__(self, link, filename, graph_link, graph_filename):\n",
        "    self.data = self.dataset_txt_file_download(link, filename)\n",
        "    self.friends = self.dataset_txt_file_download(graph_link, graph_filename)\n",
        "\n",
        "  def dataset_txt_file_download(self, link, file_name):\n",
        "    base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
        "    public_key = link\n",
        "    final_url = base_url + urlencode(dict(public_key=public_key))\n",
        "    response = requests.get(final_url)\n",
        "    download_url = response.json()['href']\n",
        "    download_response = requests.get(download_url)\n",
        "\n",
        "    with open(file_name, 'wb') as f:\n",
        "      f.write(download_response.content)\n",
        "\n",
        "    df = pd.read_csv(file_name, sep=\"\\t\", header = None)\n",
        "    return df\n",
        "\n",
        "  def preprocess(self, num_quantiles, num_users):\n",
        "    self.data.columns = ['user', 'check-in time', 'latitude', 'longitude', 'location_id']\n",
        "    self.data['longitude_bin'] = pd.qcut(self.data.longitude, q=num_quantiles, labels = [i for i in range(0, 15)])\n",
        "    self.data['latitude_bin'] = pd.qcut(self.data.latitude, q=num_quantiles, labels = [i for i in range(0, 15)])\n",
        "    self.data['longitude_bin'] = self.data['longitude_bin'].astype('int64')\n",
        "    self.data['latitude_bin'] = self.data['latitude_bin'].astype('int64')\n",
        "    self.data['location_id_bin'] = list(zip(self.data.latitude_bin, self.data.longitude_bin))\n",
        "    self.data['place'] = list(zip(self.data.latitude, self.data.longitude))\n",
        "    self.data['location_id_bin'] = self.data['location_id_bin'].astype('str')\n",
        "\n",
        "    self.friends.columns = ['1st friend', '2nd friend']\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    self.data.location_id_bin = le.fit_transform(self.data.location_id_bin.values)\n",
        "    self.sectors = self.data.groupby('location_id_bin').agg({'place':lambda x: list(x)}).reset_index()\n",
        "\n",
        "    self.data = self.data.sort_values('check-in time')\n",
        "    self.data['check-in time'] = pd.to_datetime(self.data['check-in time'])\n",
        "    self.data[\"check-in time\"] = self.data['check-in time'].map(lambda x: int(x.timestamp()))\n",
        "\n",
        "    self.users = self.data.groupby('user').agg({'location_id_bin':lambda x: list(x), 'check-in time':lambda x: list(x)}).reset_index()\n",
        "    self.users = self.users[self.users.location_id_bin.map(lambda x: len(x) > 3)]\n",
        "\n",
        "    self.friends = self.friends[self.friends['1st friend'].isin(self.users.user.unique())].reset_index().drop(['index'], axis=1)\n",
        "    self.friends = self.friends[self.friends['2nd friend'].isin(self.users.user.unique())].reset_index().drop(['index'], axis=1)\n",
        "\n",
        "    self.reset_id()\n",
        "    self.reset_edges()\n",
        "    self.reset_users()\n",
        "\n",
        "    self.users = self.users[self.users['user'] <= num_users]\n",
        "\n",
        "    self.friends = self.friends[(self.friends['1st friend'] <= num_users )& (self.friends['2nd friend'] <= num_users)]\n",
        "\n",
        "\n",
        "  def reset_id(self):\n",
        "    self.user_id = {}\n",
        "    id = 0\n",
        "    for user in self.users.user:\n",
        "      self.user_id[user] = id\n",
        "      id += 1\n",
        "    self.users = self.users.reset_index()\n",
        "\n",
        "  def reset_edges(self):\n",
        "    for edge in range(0, self.friends.shape[0]):\n",
        "      self.friends.loc[edge, '1st friend'] = self.user_id[self.friends.loc[edge, '1st friend']]\n",
        "    for edge in range(0, self.friends.shape[0]):\n",
        "      self.friends.loc[edge, '2nd friend'] = self.user_id[self.friends.loc[edge, '2nd friend']]\n",
        "\n",
        "  def reset_users(self):\n",
        "    for user in range(0, self.users.shape[0]):\n",
        "      self.users.loc[user, 'user'] = self.user_id[self.users.loc[user, 'user']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting to JSON"
      ],
      "metadata": {
        "id": "RUbT1UuevzTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gather_user_history(act_list, time_list, n_users, n_bins, n_context):\n",
        "    user_history = np.zeros((n_users, n_bins, n_context), dtype=np.int32)\n",
        "    for u in range(0, n_users):\n",
        "        one_act_list = act_list[u]\n",
        "        one_time_list = time_list[u]\n",
        "        for t in range(0, n_bins):\n",
        "            t_list = [i for i, x in enumerate(one_time_list) if x == t]\n",
        "            loop_t = t - 1\n",
        "            if loop_t >= 0:\n",
        "                while len(t_list) < n_context:\n",
        "                    temp_list = [i for i, x in enumerate(one_time_list) if x == loop_t]\n",
        "                    t_list = temp_list + t_list\n",
        "                    loop_t -= 1\n",
        "                    if loop_t - 1 < 0:\n",
        "                        break\n",
        "            if len(t_list) == 0:\n",
        "                t_list = [0] * n_context\n",
        "            now_index = t_list[-n_context:]\n",
        "            begin_ind = now_index[0]\n",
        "            end_ind = now_index[-1]\n",
        "            current_history = one_act_list[begin_ind: end_ind + 1]\n",
        "            if len(current_history) < n_context:\n",
        "                current_history = [0] * (n_context - len(current_history)) + current_history\n",
        "            user_history[u, t, :] = current_history\n",
        "\n",
        "    return user_history"
      ],
      "metadata": {
        "id": "njLfqa2Etsdw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_timestamp(users, n_context, seq_len):\n",
        "    act_list = list()\n",
        "    time_list = list()\n",
        "    user_list = list()\n",
        "    max_timestamp = -1.0\n",
        "    min_timestamp = float('inf')\n",
        "    for i in range(users.shape[0]):\n",
        "      t_item_list = list()\n",
        "      t_time_list = list()\n",
        "\n",
        "      user = users.loc[i, 'user']\n",
        "      entries = users.loc[i, 'location_id_bin']\n",
        "      for j in range(len(entries)):\n",
        "        item, time_stamp = users.loc[i, 'location_id_bin'][j], users.loc[i, 'check-in time'][j]\n",
        "        t_item_list.append(int(item))\n",
        "        t_time_list.append(int(time_stamp))\n",
        "\n",
        "        if min_timestamp > int(time_stamp):\n",
        "            min_timestamp = int(time_stamp)\n",
        "        if max_timestamp < int(time_stamp):\n",
        "            max_timestamp = int(time_stamp)\n",
        "\n",
        "      act_list.append(t_item_list[0: seq_len])\n",
        "      time_list.append(t_time_list[0: seq_len])\n",
        "      user_list.append(user)\n",
        "    print('act list', len(act_list))\n",
        "    print('time list', len(time_list))\n",
        "    print('user list', len(user_list))\n",
        "\n",
        "    print(max_timestamp, min_timestamp)\n",
        "\n",
        "    new_time_list = list()\n",
        "    num_bins = 0\n",
        "\n",
        "\n",
        "    num_bins = 12\n",
        "    min_seq_len = 25\n",
        "\n",
        "\n",
        "    times_bins = np.linspace(min_timestamp, max_timestamp + 1, num=num_bins, dtype=np.int32)\n",
        "    for a_time_list in time_list:\n",
        "        temp_time_list = (np.digitize(np.asarray(a_time_list), times_bins) - 1).tolist()\n",
        "        new_time_list.append(temp_time_list)\n",
        "    print(len(time_list), len(new_time_list))\n",
        "\n",
        "    n_users = users.shape[0]\n",
        "    user_history = gather_user_history(act_list, new_time_list, n_users, num_bins, n_context)\n",
        "\n",
        "    all_examples = []\n",
        "    for i in range(0, len(act_list)):\n",
        "\n",
        "        act_seq = act_list[i]\n",
        "        time_seq = new_time_list[i]\n",
        "\n",
        "\n",
        "        entry = {'items': act_seq,\n",
        "            'timestamps': time_seq,\n",
        "            'seq_len': len(act_seq),\n",
        "            'user' : user_list[i]\n",
        "        }\n",
        "\n",
        "        all_examples.append(entry)\n",
        "\n",
        "    return all_examples, user_history, num_bins"
      ],
      "metadata": {
        "id": "VYjm6ZIsqJjE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset('https://disk.yandex.ru/d/KVm7gIom6YooWA', 'Gowalla_totalCheckins.txt', 'https://disk.yandex.ru/d/Sr3FpAa7WG4GdA', 'Gowalla_edges.txt')\n",
        "dataset.preprocess(15, 20001)"
      ],
      "metadata": {
        "id": "LzBvoxe6smFb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_examples, user_history, num_bins = load_dataset_timestamp(dataset.users, 128, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNHskKEDubn0",
        "outputId": "7e7156df-6061-4750-de98-b0d36cbf6996"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "act list 20002\n",
            "time list 20002\n",
            "user list 20002\n",
            "1287776788 1233724658\n",
            "20002 20002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_examples[1]['items']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0ywoBcTvVj6",
        "outputId": "ac349008-c075-44c8-c7bd-1ac10528efda"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[24, 35, 35, 35, 173, 173, 173, 173, 173, 185, 185, 35]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UserDataset():\n",
        "  def __init__(self, data, max_len):\n",
        "    self.data = data\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    user = self.data[idx]\n",
        "    seq_len = user['seq_len']\n",
        "\n",
        "    tr_act_seq = np.zeros((self.max_len,)).astype('int32')\n",
        "    tr_act_seq[:seq_len] = np.array(user['train_act_seq'])\n",
        "    tr_act_seq = np.transpose(tr_act_seq)\n",
        "\n",
        "    tr_time_seq = np.zeros((self.max_len,)).astype('int32')\n",
        "    tr_time_seq[:seq_len] = user['train_time_seq']\n",
        "    tr_time_seq = np.transpose(tr_time_seq)\n",
        "\n",
        "    t_act_seq = np.zeros((self.max_len, )).astype('int32')\n",
        "    t_act_seq[:seq_len] = user['test_act_seq']\n",
        "    t_act_seq = np.transpose(t_act_seq)\n",
        "\n",
        "    t_time_seq = np.zeros((self.max_len, )).astype('int32')\n",
        "    t_time_seq[:seq_len] = user['test_time_seq']\n",
        "    t_time_seq = np.transpose(t_time_seq)\n",
        "\n",
        "\n",
        "    return user['user'], tr_act_seq, \\\n",
        "    tr_time_seq, user['train_act_label'], \\\n",
        "    user['train_time_label'], t_act_seq, \\\n",
        "    t_time_seq, user['test_act_label'], \\\n",
        "    user['test_time_label'], user['seq_len']"
      ],
      "metadata": {
        "id": "xsXjI3eRxKzq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(RecModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(128, 186)\n",
        "    self.rnn = nn.RNN(128, 128, batch_first = True)\n",
        "    self.norm = nn.BatchNorm1d(128)\n",
        "\n",
        "  def forward(self, x, seq_len):\n",
        "\n",
        "    x, h = self.rnn(x)\n",
        "    hx = torch.zeros(x.shape[0], x.shape[2])\n",
        "    for i in range(hx.shape[0]):\n",
        "      hx[i] = x[i][seq_len - 1]\n",
        "    # hx = self.norm(hx)\n",
        "\n",
        "    x = self.fc1(hx)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "851YKIg1x13j"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Recommender"
      ],
      "metadata": {
        "id": "Sm6mfL_I353r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Recommender():\n",
        "\n",
        "  def __init__(self, num_classes):\n",
        "    self.item_emb  = nn.init.xavier_uniform_(torch.empty(num_classes, 128))\n",
        "\n",
        "\n",
        "  def get_rec(self, user_json):\n",
        "    comb_input = np.concatenate([np.expand_dims(user_json['items'], axis=-1),\n",
        "                                                np.expand_dims(user_json['timestamps'], axis=-1)], axis=1)\n",
        "\n",
        "    input_emb = self.item_emb[comb_input[:, 0]]\n",
        "    input_emb = input_emb.unsqueeze(0)\n",
        "    rec_model = RecModel()\n",
        "\n",
        "    # load saved model\n",
        "    rec_model.load_state_dict(torch.load('rec_model.pth'))\n",
        "    probs = rec_model(input_emb, user_json['seq_len'])\n",
        "    prediction = torch.argmax(probs, axis = 1).item()\n",
        "    places = self.get_places(prediction)\n",
        "\n",
        "    return self.rec_to_json(places, user_json['user'])\n",
        "\n",
        "  def rec_to_json(self, places, user_id):\n",
        "    rec_answer = {}\n",
        "    rec_answer['user'] = user_id\n",
        "    rec_answer['recommendations'] = []\n",
        "    for place in places:\n",
        "      rec_answer['recommendations'].append({'latitude' : place[0], 'longitude' : place[1]})\n",
        "    return rec_answer\n",
        "\n",
        "\n",
        "  def get_places(self, prediction):\n",
        "    sector = dataset.sectors.loc[prediction, 'place']\n",
        "    indices = np.arange(len(sector))\n",
        "    random_indices = random.choices(indices, k=10)\n",
        "\n",
        "    places = []\n",
        "    for index in random_indices:\n",
        "      places.append(sector[index])\n",
        "    return places"
      ],
      "metadata": {
        "id": "PspbwTelub35"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommender = Recommender(186)\n",
        "recommendation = recommender.get_rec(data_examples[1])"
      ],
      "metadata": {
        "id": "gx6VkO6gmMHM"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ответ модели на запрос в формате JSON - рекомендуется 10 пар координат (мест)"
      ],
      "metadata": {
        "id": "sH8xh7z-Twge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(recommendation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN7z-DZRAK3U",
        "outputId": "fc387f1f-0da3-4a4e-a610-9017b24097dd"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'user': 1, 'recommendations': [{'latitude': 47.6136782429, 'longitude': -122.3166704178}, {'latitude': 48.46635608, 'longitude': -123.30949773}, {'latitude': 47.6133123, 'longitude': -122.34547317}, {'latitude': 47.6086585858, 'longitude': -122.3407244682}, {'latitude': 48.38932338, 'longitude': -122.498170007}, {'latitude': 48.42887055, 'longitude': -123.360541}, {'latitude': 47.6110780628, 'longitude': -122.337256372}, {'latitude': 49.002005803, 'longitude': -122.7564239502}, {'latitude': 47.61769525, 'longitude': -122.3457130667}, {'latitude': 47.6191235592, 'longitude': -122.3487303387}]}\n"
          ]
        }
      ]
    }
  ]
}