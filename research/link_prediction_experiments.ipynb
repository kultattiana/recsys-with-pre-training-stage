{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-17T22:19:45.084514Z",
          "iopub.status.busy": "2024-05-17T22:19:45.083733Z",
          "iopub.status.idle": "2024-05-17T22:19:53.428140Z",
          "shell.execute_reply": "2024-05-17T22:19:53.427371Z",
          "shell.execute_reply.started": "2024-05-17T22:19:45.084473Z"
        },
        "id": "_xUxn47qIL8b",
        "outputId": "1f0b8b5a-8657-4baf-99ba-2280758eb210",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch-scatter 2.1.2+pt20cu118\n",
            "Uninstalling torch-scatter-2.1.2+pt20cu118:\n",
            "  Successfully uninstalled torch-scatter-2.1.2+pt20cu118\n",
            "Found existing installation: torch-sparse 0.6.18+pt20cu118\n",
            "Uninstalling torch-sparse-0.6.18+pt20cu118:\n",
            "  Successfully uninstalled torch-sparse-0.6.18+pt20cu118\n",
            "Found existing installation: torch_geometric 2.5.3\n",
            "Uninstalling torch_geometric-2.5.3:\n",
            "  Successfully uninstalled torch_geometric-2.5.3\n",
            "Found existing installation: torch-cluster 1.6.3+pt20cu118\n",
            "Uninstalling torch-cluster-1.6.3+pt20cu118:\n",
            "  Successfully uninstalled torch-cluster-1.6.3+pt20cu118\n",
            "Found existing installation: torch-spline-conv 1.2.2+pt20cu118\n",
            "Uninstalling torch-spline-conv-1.2.2+pt20cu118:\n",
            "  Successfully uninstalled torch-spline-conv-1.2.2+pt20cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "%pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster torch-spline-conv  --y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-17T22:19:53.432245Z",
          "iopub.status.busy": "2024-05-17T22:19:53.429552Z",
          "iopub.status.idle": "2024-05-17T22:20:24.779005Z",
          "shell.execute_reply": "2024-05-17T22:20:24.778144Z",
          "shell.execute_reply.started": "2024-05-17T22:19:53.432200Z"
        },
        "id": "VtTAl7ZqSn3K",
        "outputId": "39d2ec52-20f8-4b9f-b4c0-beed9c1b0673",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt20cu118\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt20cu118\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.22.4)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt20cu118\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (886 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.6/886.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt20cu118\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m847.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /kernel/lib/python3.10/site-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.8.5)\n",
            "Requirement already satisfied: requests in /kernel/lib/python3.10/site-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /kernel/lib/python3.10/site-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Collecting psutil>=5.8.0 (from torch-geometric)\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /kernel/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /kernel/lib/python3.10/site-packages (from aiohttp->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /kernel/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /kernel/lib/python3.10/site-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /kernel/lib/python3.10/site-packages (from requests->torch-geometric) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.10/site-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psutil, torch-geometric\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ml-kernel 0.0.1 requires psutil<=5.7.3,>=5.7.0, but you have psutil 5.9.8 which is incompatible.\n",
            "dvc 2.58.2 requires platformdirs<4,>=3.1.1, but you have platformdirs 4.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed psutil-5.9.8 torch-geometric-2.5.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "%pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "%pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "%pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "%pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "%pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:24.781848Z",
          "iopub.status.busy": "2024-05-17T22:20:24.781045Z",
          "iopub.status.idle": "2024-05-17T22:20:36.564326Z",
          "shell.execute_reply": "2024-05-17T22:20:36.563490Z",
          "shell.execute_reply.started": "2024-05-17T22:20:24.781804Z"
        },
        "id": "2H43ZmFt-Tbi",
        "outputId": "717b843e-40c7-4d20-a7e2-c6aac398049c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: networkit 11.0\n",
            "Uninstalling networkit-11.0:\n",
            "  Successfully uninstalled networkit-11.0\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting networkit\n",
            "  Downloading networkit-11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from networkit) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from networkit) (1.22.4)\n",
            "Downloading networkit-11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: networkit\n",
            "Successfully installed networkit-11.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%pip uninstall networkit\n",
        "%pip install networkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:36.566511Z",
          "iopub.status.busy": "2024-05-17T22:20:36.565952Z",
          "iopub.status.idle": "2024-05-17T22:20:42.082822Z",
          "shell.execute_reply": "2024-05-17T22:20:42.082028Z",
          "shell.execute_reply.started": "2024-05-17T22:20:36.566471Z"
        },
        "id": "My_CXpFlxUvA",
        "outputId": "9512ca5a-cf15-45f0-fb89-f5da4279f56d",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\t\t\t<script type=\"text/javascript\">\n",
              "\t\t\t<!--\n",
              "\t\t\t\t\n",
              "\t\t\t{\n",
              "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
              "\t\t\t\tif (element) {\n",
              "\t\t\t\t\telement.parentNode.removeChild(element);\n",
              "\t\t\t\t}\n",
              "\t\t\t\telement = document.createElement('script');\n",
              "\t\t\t\telement.type = 'text/javascript';\n",
              "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
              "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
              "\t\t\t\tdocument.head.appendChild(element);\n",
              "\t\t\t}\n",
              "\t\t\n",
              "\t\t\t\t\n",
              "\t\t\t{\n",
              "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
              "\t\t\t\tif (element) {\n",
              "\t\t\t\t\telement.parentNode.removeChild(element);\n",
              "\t\t\t\t}\n",
              "\t\t\t\telement = document.createElement('style');\n",
              "\t\t\t\telement.type = 'text/css';\n",
              "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
              "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
              "\t\t\t\tdocument.head.appendChild(element);\n",
              "\t\t\t}\n",
              "\t\t\n",
              "\t\t\t\t\n",
              "\t\t\t{\n",
              "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
              "\t\t\t\tif (element) {\n",
              "\t\t\t\t\telement.parentNode.removeChild(element);\n",
              "\t\t\t\t}\n",
              "\t\t\t\telement = document.createElement('div');\n",
              "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
              "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
              "\t\t\t\tdocument.body.appendChild(element);\n",
              "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
              "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
              "\t\t\t\t}\n",
              "\t\t\t}\n",
              "\t\t\n",
              "\t\t\t-->\n",
              "\t\t\t</script>\n",
              "\t\t"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import random\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "import networkx as nx\n",
        "import networkit as nk\n",
        "from networkit import vizbridges\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import subgraph\n",
        "from torch_geometric.nn import GATv2Conv, GCNConv, SAGEConv\n",
        "from torch_geometric.loader import LinkNeighborLoader, LinkLoader\n",
        "from torch_geometric.transforms import RandomLinkSplit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:42.086139Z",
          "iopub.status.busy": "2024-05-17T22:20:42.083914Z",
          "iopub.status.idle": "2024-05-17T22:20:42.114207Z",
          "shell.execute_reply": "2024-05-17T22:20:42.113528Z",
          "shell.execute_reply.started": "2024-05-17T22:20:42.086101Z"
        },
        "id": "ox0nfVzoKySr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:42.115864Z",
          "iopub.status.busy": "2024-05-17T22:20:42.115131Z",
          "iopub.status.idle": "2024-05-17T22:20:42.127743Z",
          "shell.execute_reply": "2024-05-17T22:20:42.127143Z",
          "shell.execute_reply.started": "2024-05-17T22:20:42.115834Z"
        },
        "id": "SzURh5j3NowJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch_cluster\n",
        "import torch_scatter\n",
        "import torch_geometric\n",
        "import torch_sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:42.128931Z",
          "iopub.status.busy": "2024-05-17T22:20:42.128544Z",
          "iopub.status.idle": "2024-05-17T22:20:42.140995Z",
          "shell.execute_reply": "2024-05-17T22:20:42.140285Z",
          "shell.execute_reply.started": "2024-05-17T22:20:42.128899Z"
        },
        "id": "6o_NKJOFI09u",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:42.144131Z",
          "iopub.status.busy": "2024-05-17T22:20:42.143506Z",
          "iopub.status.idle": "2024-05-17T22:20:42.157246Z",
          "shell.execute_reply": "2024-05-17T22:20:42.156597Z",
          "shell.execute_reply.started": "2024-05-17T22:20:42.144097Z"
        },
        "id": "ChHoOY5oM4y5",
        "outputId": "69107b6d-d550-41cb-c131-e03ec839b772",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:42.159753Z",
          "iopub.status.busy": "2024-05-17T22:20:42.158632Z",
          "iopub.status.idle": "2024-05-17T22:20:42.178789Z",
          "shell.execute_reply": "2024-05-17T22:20:42.178069Z",
          "shell.execute_reply.started": "2024-05-17T22:20:42.159696Z"
        },
        "id": "WiHOR41FI09u",
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(200)\n",
        "np.random.seed(200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ1KY0fsx_Nm"
      },
      "source": [
        "### Util function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:42.180476Z",
          "iopub.status.busy": "2024-05-17T22:20:42.179696Z",
          "iopub.status.idle": "2024-05-17T22:20:42.199804Z",
          "shell.execute_reply": "2024-05-17T22:20:42.199031Z",
          "shell.execute_reply.started": "2024-05-17T22:20:42.180437Z"
        },
        "id": "e4mUB-lFrI5U",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def load_dataset_timestamp( n_users, n_context, seq_len):\n",
        "    act_list = []\n",
        "    time_list = []\n",
        "    user_list = []\n",
        "\n",
        "    max_timestamp = -1.0\n",
        "    min_timestamp = float('inf')\n",
        "\n",
        "    with open('gowalla_user_activity.txt', 'r') as raw_file:\n",
        "        for line in raw_file:\n",
        "            t_item_list = []\n",
        "            t_time_list = []\n",
        "            user = int(line.split(':')[0])\n",
        "            entries = line.split()[1:]\n",
        "            for a_entry in entries:\n",
        "                item, time_stamp = a_entry.split(':')\n",
        "                t_item_list.append(int(item.strip()))\n",
        "                t_time_list.append(int(time_stamp.strip()))\n",
        "\n",
        "                if min_timestamp > int(time_stamp.strip()):\n",
        "                    min_timestamp = int(time_stamp.strip())\n",
        "                if max_timestamp < int(time_stamp.strip()):\n",
        "                    max_timestamp = int(time_stamp.strip())\n",
        "\n",
        "            act_list.append(t_item_list[0: seq_len])\n",
        "            time_list.append(t_time_list[0: seq_len])\n",
        "            user_list.append(user)\n",
        "\n",
        "    new_time_list = []\n",
        "    num_bins = 0\n",
        "\n",
        "    times_bins = np.linspace(min_timestamp, max_timestamp + 1, num=num_bins, dtype=np.int32)\n",
        "    for a_time_list in time_list:\n",
        "        temp_time_list = (np.digitize(np.asarray(a_time_list), times_bins) - 1).tolist()\n",
        "        new_time_list.append(temp_time_list)\n",
        "\n",
        "    all_examples = []\n",
        "    for i in range(0, len(act_list)):\n",
        "\n",
        "        train_act_seq = act_list[i][:-2]\n",
        "\n",
        "        train_time_seq = new_time_list[i][:-2]\n",
        "\n",
        "        train_act_label = act_list[i][-2]\n",
        "        train_time_label = new_time_list[i][-2]\n",
        "\n",
        "        test_act_seq = act_list[i][1:-1]\n",
        "        test_time_seq = new_time_list[i][1:-1]\n",
        "\n",
        "        test_act_label = act_list[i][-1]\n",
        "        test_time_label = new_time_list[i][-1]\n",
        "\n",
        "        entry = {\n",
        "            'train_act_seq': train_act_seq,\n",
        "            'train_time_seq': train_time_seq,\n",
        "            'train_act_label': train_act_label,\n",
        "            'train_time_label': train_time_label,\n",
        "            'test_act_seq': test_act_seq,\n",
        "            'test_time_seq': test_time_seq,\n",
        "            'test_act_label': test_act_label,\n",
        "            'test_time_label': test_time_label,\n",
        "            'seq_len': len(train_act_seq),\n",
        "            'user': user_list[i]\n",
        "        }\n",
        "\n",
        "        all_examples.append(entry)\n",
        "\n",
        "    return all_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:42.201086Z",
          "iopub.status.busy": "2024-05-17T22:20:42.200710Z",
          "iopub.status.idle": "2024-05-17T22:20:45.418729Z",
          "shell.execute_reply": "2024-05-17T22:20:45.417945Z",
          "shell.execute_reply.started": "2024-05-17T22:20:42.201055Z"
        },
        "id": "mDM_Z8mjKWoe"
      },
      "outputs": [],
      "source": [
        "data_examples = load_dataset_timestamp(20001, 128, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-17T22:20:45.420271Z",
          "iopub.status.busy": "2024-05-17T22:20:45.419760Z",
          "iopub.status.idle": "2024-05-17T22:20:45.446674Z",
          "shell.execute_reply": "2024-05-17T22:20:45.445993Z",
          "shell.execute_reply.started": "2024-05-17T22:20:45.420220Z"
        },
        "id": "YudVMZuAJLwx"
      },
      "outputs": [],
      "source": [
        "def filter(x):\n",
        "  return [user for user in users if user not in x]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu-By-7F2tdy"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:58:48.462794Z",
          "iopub.status.busy": "2024-05-16T18:58:48.461447Z",
          "iopub.status.idle": "2024-05-16T18:58:48.522880Z",
          "shell.execute_reply": "2024-05-16T18:58:48.521802Z",
          "shell.execute_reply.started": "2024-05-16T18:58:48.462632Z"
        },
        "id": "FmEaZ3v-PPB2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def print_metrics(hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100):\n",
        "    print(f'hits@1: {hits1:.6f}, hits@5: {hits5:.6f}, hits@10: {hits10:.6f}, hits@20: {hits20:.6f}')\n",
        "    print(f'hits@50: {hits50:.6f}, hits@100: {hits100:.6f}')\n",
        "    print(f'map@1: {map1:.6f}, map@5: {map5:.6f}, map@10: {map10:.6f}, map@20: {map20:.6f}')\n",
        "    print(f'map@50: {map50:.6f}, map@100: {map100:.6f}')\n",
        "    print(f'ndcg@1: {ndcg1:.6f}, ndcg@5: {ndcg5:.6f}, ndcg@10: {ndcg10:.6f}, ndcg@20: {ndcg20:.6f}')\n",
        "    print(f'ndcg@50: {ndcg50:.6f}, ndcg@100: {ndcg100:.6f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:58:48.525416Z",
          "iopub.status.busy": "2024-05-16T18:58:48.524231Z",
          "iopub.status.idle": "2024-05-16T18:58:48.589950Z",
          "shell.execute_reply": "2024-05-16T18:58:48.588913Z",
          "shell.execute_reply.started": "2024-05-16T18:58:48.525357Z"
        },
        "id": "wveiHrarPAc2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def apk(actual, predicted, k=10):\n",
        "\n",
        "    if len(predicted) > k:\n",
        "        predicted = predicted[:k]\n",
        "\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "\n",
        "    for i, p in enumerate(predicted):\n",
        "        if p in actual and p not in predicted[:i]:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i + 1.0)\n",
        "\n",
        "    if not actual:\n",
        "        return 0.0\n",
        "\n",
        "    return score / min(len(actual), k)\n",
        "\n",
        "\n",
        "def mapk(y_prob, y, k=10):\n",
        "\n",
        "    predicted = [np.argsort(p_)[-k:][::-1] for p_ in y_prob]\n",
        "    actual = [[y_] for y_ in y]\n",
        "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n",
        "\n",
        "\n",
        "def hits_k(y_prob, y, k=10):\n",
        "    acc = []\n",
        "    for p_, y_ in zip(y_prob, y):\n",
        "        top_k = p_.argsort()[-k:][::-1]\n",
        "        acc += [1. if y_ in top_k else 0.]\n",
        "from sklearn.metrics import ndcg_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:58:48.592427Z",
          "iopub.status.busy": "2024-05-16T18:58:48.591314Z",
          "iopub.status.idle": "2024-05-16T18:58:48.640409Z",
          "shell.execute_reply": "2024-05-16T18:58:48.639293Z",
          "shell.execute_reply.started": "2024-05-16T18:58:48.592376Z"
        },
        "id": "9rYVlp7z3B7S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_metrics_(probs, labels_batch, test_one_hot):\n",
        "    hits1 = top_k_accuracy_score(labels_batch, probs.cpu().detach().numpy(), k=1, labels = classes)\n",
        "    hits5 = top_k_accuracy_score(labels_batch, probs.cpu().detach().numpy(), k=5, labels = classes)\n",
        "    hits10 = top_k_accuracy_score(labels_batch, probs.cpu().detach().numpy(), k=10, labels = classes)\n",
        "    hits20 = top_k_accuracy_score(labels_batch, probs.cpu().detach().numpy(), k=20, labels = classes)\n",
        "    hits50= top_k_accuracy_score(labels_batch, probs.cpu().detach().numpy(), k=50, labels = classes)\n",
        "    hits100 = top_k_accuracy_score(labels_batch, probs.cpu().detach().numpy(), k=100, labels = classes)\n",
        "\n",
        "    map1 = mapk(y_prob=probs.cpu().detach().numpy(), y = labels_batch, k=1)\n",
        "    map5 = mapk(y_prob=probs.cpu().detach().numpy(), y = labels_batch, k=5)\n",
        "    map10 = mapk(y_prob=probs.cpu().detach().numpy(), y = labels_batch, k=10)\n",
        "    map20 = mapk(y_prob=probs.cpu().detach().numpy(), y = labels_batch, k=20)\n",
        "    map50 = mapk(y_prob=probs.cpu().detach().numpy(), y = labels_batch, k=50)\n",
        "    map100 = mapk(y_prob=probs.cpu().detach().numpy(), y = labels_batch, k=100)\n",
        "\n",
        "    ndcg1 = ndcg_score(test_one_hot, probs.cpu().detach().numpy(), k=1)\n",
        "    ndcg5 = ndcg_score(test_one_hot, probs.cpu().detach().numpy(), k=5)\n",
        "    ndcg10 = ndcg_score(test_one_hot, probs.cpu().detach().numpy(), k=10)\n",
        "    ndcg20 = ndcg_score(test_one_hot, probs.cpu().detach().numpy(), k=20)\n",
        "    ndcg50 = ndcg_score(test_one_hot, probs.cpu().detach().numpy(), k=50)\n",
        "    ndcg100 = ndcg_score(test_one_hot, probs.cpu().detach().numpy(), k=100)\n",
        "    return hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqqpRxijx4PW"
      },
      "source": [
        "### User representations dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:58:48.642652Z",
          "iopub.status.busy": "2024-05-16T18:58:48.641750Z",
          "iopub.status.idle": "2024-05-16T18:58:48.697397Z",
          "shell.execute_reply": "2024-05-16T18:58:48.696369Z",
          "shell.execute_reply.started": "2024-05-16T18:58:48.642562Z"
        },
        "id": "HUI0f58FKSTh",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class UserDataset():\n",
        "    def __init__(self, user_representations):\n",
        "        self.user_representations = user_representations\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.user_representations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_id = idx\n",
        "        if idx not in self.user_representations.keys():\n",
        "          return user_id, self.user_representations[1][0], 0\n",
        "        return user_id, self.user_representations[idx][0], self.user_representations[idx][1].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:58:48.699515Z",
          "iopub.status.busy": "2024-05-16T18:58:48.698528Z",
          "iopub.status.idle": "2024-05-16T18:58:48.722515Z",
          "shell.execute_reply": "2024-05-16T18:58:48.721414Z",
          "shell.execute_reply.started": "2024-05-16T18:58:48.699460Z"
        },
        "id": "YRdEhQcAuHCj",
        "tags": []
      },
      "outputs": [],
      "source": [
        "num_classes = 3883\n",
        "classes = np.arange(0, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-15T21:58:29.894667Z",
          "iopub.status.busy": "2024-05-15T21:58:29.893651Z",
          "iopub.status.idle": "2024-05-15T21:58:29.931942Z",
          "shell.execute_reply": "2024-05-15T21:58:29.930654Z",
          "shell.execute_reply.started": "2024-05-15T21:58:29.894615Z"
        },
        "id": "BNkXXTfLwZsw",
        "tags": []
      },
      "outputs": [],
      "source": [
        "item_emb  = nn.init.xavier_uniform_(torch.empty(num_classes, 128))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "400qrYjQ02gT"
      },
      "source": [
        "### RNN + Graph Link prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:58:48.724283Z",
          "iopub.status.busy": "2024-05-16T18:58:48.723726Z",
          "iopub.status.idle": "2024-05-16T18:58:48.750937Z",
          "shell.execute_reply": "2024-05-16T18:58:48.749825Z",
          "shell.execute_reply.started": "2024-05-16T18:58:48.724237Z"
        },
        "id": "NnT2tBdGnrsE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "num_classes = 3883\n",
        "classes = np.arange(0, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:58:48.753524Z",
          "iopub.status.busy": "2024-05-16T18:58:48.752130Z",
          "iopub.status.idle": "2024-05-16T18:58:53.058028Z",
          "shell.execute_reply": "2024-05-16T18:58:53.056637Z",
          "shell.execute_reply.started": "2024-05-16T18:58:48.753470Z"
        },
        "id": "E3ZTBmKsM0fy",
        "tags": []
      },
      "outputs": [],
      "source": [
        "users = load_dataset_timestamp(20001, 128, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:58:53.060631Z",
          "iopub.status.busy": "2024-05-16T18:58:53.059721Z",
          "iopub.status.idle": "2024-05-16T18:58:53.221425Z",
          "shell.execute_reply": "2024-05-16T18:58:53.220339Z",
          "shell.execute_reply.started": "2024-05-16T18:58:53.060560Z"
        },
        "id": "5UMgTVzJnJ8w",
        "tags": []
      },
      "outputs": [],
      "source": [
        "friends = pd.read_csv('gowalla_edges.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph construction"
      ],
      "metadata": {
        "id": "rxPvtKcQqn0s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:58:53.241347Z",
          "iopub.status.busy": "2024-05-16T18:58:53.240736Z",
          "iopub.status.idle": "2024-05-16T18:59:00.708418Z",
          "shell.execute_reply": "2024-05-16T18:59:00.707233Z",
          "shell.execute_reply.started": "2024-05-16T18:58:53.241304Z"
        },
        "id": "zFBHTlHaPQbx",
        "tags": []
      },
      "outputs": [],
      "source": [
        "Gcl = nx.Graph()\n",
        "for i in range(len(users)):\n",
        "  if users[i]['user'] not in Gcl.nodes():\n",
        "      Gcl.add_node(users[i]['user'], weight=10, color='seagreen')\n",
        "for i in range(len(friends)):\n",
        "  Gcl.add_edge(friends.loc[i, '1st friend'], friends.loc[i, '2nd friend'], color = 'blue')\n",
        "\n",
        "\n",
        "nodes = list(Gcl.nodes())\n",
        "node_colors = [Gcl.nodes[node]['color'] for node in Gcl.nodes]\n",
        "node_weights = [Gcl.nodes[node]['weight'] for node in Gcl.nodes]\n",
        "edge_colors = [Gcl.edges[edge]['color'] for edge in Gcl.edges]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:00.711013Z",
          "iopub.status.busy": "2024-05-16T18:59:00.709918Z",
          "iopub.status.idle": "2024-05-16T18:59:00.993620Z",
          "shell.execute_reply": "2024-05-16T18:59:00.992448Z",
          "shell.execute_reply.started": "2024-05-16T18:59:00.710959Z"
        },
        "id": "Dez6obQePj81",
        "tags": []
      },
      "outputs": [],
      "source": [
        "graphid2pid = {}\n",
        "pid2graphid = {}\n",
        "\n",
        "s = 0\n",
        "for node_id in Gcl.nodes():\n",
        "    pid2graphid[node_id] = s\n",
        "    graphid2pid[s] = node_id\n",
        "    s += 1\n",
        "\n",
        "graph_edges = []\n",
        "for (u, v) in Gcl.edges():\n",
        "    graph_edges.append((pid2graphid[u], pid2graphid[v]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:01.000781Z",
          "iopub.status.busy": "2024-05-16T18:59:00.999930Z",
          "iopub.status.idle": "2024-05-16T18:59:01.068354Z",
          "shell.execute_reply": "2024-05-16T18:59:01.067228Z",
          "shell.execute_reply.started": "2024-05-16T18:59:01.000736Z"
        },
        "id": "Ngj3R0fMPstY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class UserInfoDataset():\n",
        "  def __init__(self, data, max_len):\n",
        "    self.data = data\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    user = self.data[idx]\n",
        "    seq_len = user['seq_len']\n",
        "\n",
        "    tr_act_seq = np.zeros((self.max_len,)).astype('int32')\n",
        "    tr_act_seq[:seq_len] = np.array(user['train_act_seq'])\n",
        "    tr_act_seq = np.transpose(tr_act_seq)\n",
        "\n",
        "    tr_time_seq = np.zeros((self.max_len,)).astype('int32')\n",
        "    tr_time_seq[:seq_len] = user['train_time_seq']\n",
        "    tr_time_seq = np.transpose(tr_time_seq)\n",
        "\n",
        "    t_act_seq = np.zeros((self.max_len, )).astype('int32')\n",
        "    t_act_seq[:seq_len] = user['test_act_seq']\n",
        "    t_act_seq = np.transpose(t_act_seq)\n",
        "\n",
        "    t_time_seq = np.zeros((self.max_len, )).astype('int32')\n",
        "    t_time_seq[:seq_len] = user['test_time_seq']\n",
        "    t_time_seq = np.transpose(t_time_seq)\n",
        "\n",
        "\n",
        "    return user['user'], tr_act_seq, \\\n",
        "    tr_time_seq, user['train_act_label'], \\\n",
        "    user['train_time_label'], t_act_seq, \\\n",
        "    t_time_seq, user['test_act_label'], \\\n",
        "    user['test_time_label'], user['seq_len']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:01.071970Z",
          "iopub.status.busy": "2024-05-16T18:59:01.071026Z",
          "iopub.status.idle": "2024-05-16T18:59:01.198863Z",
          "shell.execute_reply": "2024-05-16T18:59:01.197751Z",
          "shell.execute_reply.started": "2024-05-16T18:59:01.071917Z"
        },
        "id": "Nqqd8RNIP3zJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "user_dataset = UserInfoDataset(users, 30)\n",
        "\n",
        "n = len(user_dataset)\n",
        "\n",
        "indices = np.arange(n)\n",
        "indices = np.random.permutation(indices)\n",
        "\n",
        "train_indices = indices [:int(0.8*n)]\n",
        "test_indices = indices[int(0.8*n):]\n",
        "\n",
        "user_train_dataset = Subset(user_dataset, train_indices)\n",
        "user_test_dataset = Subset(user_dataset, test_indices)\n",
        "\n",
        "user_dataloader = DataLoader(user_dataset, batch_size = 20001, shuffle = True)\n",
        "user_train_dataloader = DataLoader(user_train_dataset, batch_size=64, shuffle=True)\n",
        "user_test_dataloader = DataLoader(user_test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "item_emb  = nn.init.xavier_uniform_(torch.empty(num_classes, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:01.200964Z",
          "iopub.status.busy": "2024-05-16T18:59:01.200287Z",
          "iopub.status.idle": "2024-05-16T18:59:03.006528Z",
          "shell.execute_reply": "2024-05-16T18:59:03.005454Z",
          "shell.execute_reply.started": "2024-05-16T18:59:01.200915Z"
        },
        "id": "_k-S30iJ_a-T",
        "tags": []
      },
      "outputs": [],
      "source": [
        "user_representations = {}\n",
        "for users, train_input, train_time, train_label, train_time_label, test_input, test_time, test_label, test_time_label, seq_len in user_dataloader:\n",
        "      comb_input = np.concatenate([np.expand_dims(train_input, axis=-1),\n",
        "                                                np.expand_dims(train_time, axis=-1)], axis=2)\n",
        "      model_input = comb_input\n",
        "      model_output = train_label\n",
        "      test_comb_input = np.concatenate([np.expand_dims(test_input, axis=-1),\n",
        "                                                np.expand_dims(test_time, axis=-1)], axis=2)\n",
        "      test_model_input = test_comb_input\n",
        "      rnn_input_emb = item_emb[model_input[:, :, 0]]\n",
        "      test_rnn_input_emb = item_emb[test_model_input[:, :, 0]]\n",
        "      for i in range(len(users)):\n",
        "        user_representations[users[i].item()] = (users[i].item(), rnn_input_emb[i], train_label[i].item(), seq_len[i].item(), test_rnn_input_emb[i], test_label[i].item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:03.008669Z",
          "iopub.status.busy": "2024-05-16T18:59:03.008054Z",
          "iopub.status.idle": "2024-05-16T18:59:03.604075Z",
          "shell.execute_reply": "2024-05-16T18:59:03.602929Z",
          "shell.execute_reply.started": "2024-05-16T18:59:03.008618Z"
        },
        "id": "I8sslFY4CQog",
        "tags": []
      },
      "outputs": [],
      "source": [
        "user_ids = []\n",
        "features = []\n",
        "train_labels = []\n",
        "seq_lens = []\n",
        "test_features = []\n",
        "test_labels = []\n",
        "for graphid in Gcl.nodes():\n",
        "    pid = graphid2pid[graphid]\n",
        "    if graphid in user_representations.keys():\n",
        "      user_ids.append(user_representations[graphid][0])\n",
        "      features.append(user_representations[graphid][1].detach().numpy())\n",
        "      train_labels.append(user_representations[graphid][2])\n",
        "      test_features.append(user_representations[graphid][4].detach().numpy())\n",
        "      seq_lens.append(user_representations[graphid][3])\n",
        "      test_labels.append(user_representations[graphid][5])\n",
        "user_ids = np.array(user_ids)\n",
        "features = np.array(features)\n",
        "train_labels = np.array(train_labels)\n",
        "test_features = np.array(test_features)\n",
        "seq_lens = np.array(seq_lens)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:03.655831Z",
          "iopub.status.busy": "2024-05-16T18:59:03.655117Z",
          "iopub.status.idle": "2024-05-16T18:59:03.830639Z",
          "shell.execute_reply": "2024-05-16T18:59:03.829464Z",
          "shell.execute_reply.started": "2024-05-16T18:59:03.655736Z"
        },
        "id": "XJTQ5dPLwEFD",
        "tags": []
      },
      "outputs": [],
      "source": [
        "dataset = Data(x=torch.tensor(features, dtype=torch.float), edge_index=torch.tensor(np.array(graph_edges).T, dtype=torch.int64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:03.833183Z",
          "iopub.status.busy": "2024-05-16T18:59:03.831861Z",
          "iopub.status.idle": "2024-05-16T18:59:03.922876Z",
          "shell.execute_reply": "2024-05-16T18:59:03.921616Z",
          "shell.execute_reply.started": "2024-05-16T18:59:03.833105Z"
        },
        "id": "2WRCuivTc82f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "dataset.user_ids = torch.tensor(user_ids, dtype=torch.int64)\n",
        "dataset.train_labels = torch.tensor(train_labels, dtype=torch.int64)\n",
        "dataset.seq_lens = torch.tensor(seq_lens, dtype=torch.int64)\n",
        "dataset.test_labels = torch.tensor(test_labels, dtype=torch.int64)\n",
        "dataset.test_features = torch.tensor(test_features, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:03.948973Z",
          "iopub.status.busy": "2024-05-16T18:59:03.948145Z",
          "iopub.status.idle": "2024-05-16T18:59:03.966190Z",
          "shell.execute_reply": "2024-05-16T18:59:03.965087Z",
          "shell.execute_reply.started": "2024-05-16T18:59:03.948915Z"
        },
        "id": "YUkok_bqkc88",
        "tags": []
      },
      "outputs": [],
      "source": [
        "link_splitter = RandomLinkSplit(\n",
        "     num_val=0.0,\n",
        "     num_test=0.0,\n",
        "     add_negative_train_samples=False,\n",
        "     disjoint_train_ratio=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:03.968776Z",
          "iopub.status.busy": "2024-05-16T18:59:03.967659Z",
          "iopub.status.idle": "2024-05-16T18:59:04.052989Z",
          "shell.execute_reply": "2024-05-16T18:59:04.051854Z",
          "shell.execute_reply.started": "2024-05-16T18:59:03.968730Z"
        },
        "id": "z-OEOjLCkz7o",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_g, val_g, test_g = link_splitter(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Data(x=torch.tensor(test_features, dtype=torch.float), edge_index=torch.tensor(np.array(graph_edges).T, dtype=torch.int64))\n",
        "test_dataset.user_info = users_info"
      ],
      "metadata": {
        "id": "Wq3gf04oq_AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZyGO1J_aF66"
      },
      "outputs": [],
      "source": [
        "test_loader = LinkNeighborLoader(\n",
        "     test_dataset,\n",
        "     num_neighbors=[-1, 10, 5],\n",
        "     batch_size=128,\n",
        "     neg_sampling_ratio=0.5\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:04.137467Z",
          "iopub.status.busy": "2024-05-16T18:59:04.136634Z",
          "iopub.status.idle": "2024-05-16T18:59:04.158982Z",
          "shell.execute_reply": "2024-05-16T18:59:04.157845Z",
          "shell.execute_reply.started": "2024-05-16T18:59:04.137419Z"
        },
        "id": "bgWW3ZOyHs8B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def negative_sampling(edge_index, num_nodes):\n",
        "    mask_1 = torch.rand(edge_index.size(1)) < 0.5\n",
        "    mask_2 = ~mask_1\n",
        "\n",
        "    neg_edge_index = edge_index.clone()\n",
        "    neg_edge_index[0, mask_1] = torch.randint(num_nodes, (mask_1.sum(),))\n",
        "    neg_edge_index[1, mask_2] = torch.randint(num_nodes, (mask_2.sum(),))\n",
        "\n",
        "    return neg_edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:04.161677Z",
          "iopub.status.busy": "2024-05-16T18:59:04.160363Z",
          "iopub.status.idle": "2024-05-16T18:59:04.181649Z",
          "shell.execute_reply": "2024-05-16T18:59:04.180562Z",
          "shell.execute_reply.started": "2024-05-16T18:59:04.161617Z"
        },
        "id": "aF95F7euVvYI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN + SAGE Conv, берем выходы RNN"
      ],
      "metadata": {
        "id": "lgTU6FcorTbY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:04.184019Z",
          "iopub.status.busy": "2024-05-16T18:59:04.182815Z",
          "iopub.status.idle": "2024-05-16T18:59:04.210856Z",
          "shell.execute_reply": "2024-05-16T18:59:04.209676Z",
          "shell.execute_reply.started": "2024-05-16T18:59:04.183968Z"
        },
        "tags": [],
        "id": "DyRkTra_qS4U"
      },
      "outputs": [],
      "source": [
        "class GraphLinkPredictionModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(GraphLinkPredictionModel, self).__init__()\n",
        "\n",
        "    self.rnn = nn.RNN(128, 128, batch_first = True)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "    self.relu = nn.Tanh()\n",
        "    self.norm = nn.BatchNorm1d(128)\n",
        "    self.head_1 = nn.Sequential(nn.Linear(256, 1))\n",
        "    self.sigmoid= nn.Sigmoid()\n",
        "    self.graphconv = SAGEConv(128, 128)\n",
        "    self.graphconv2 = SAGEConv(128, 128)\n",
        "    self.prelu1 = nn.PReLU(128)\n",
        "    self.head_2 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x, seq_len, edge_index):\n",
        "    x, h = self.rnn(x)\n",
        "    hx = torch.zeros(x.shape[0], x.shape[2])\n",
        "    for i in range(hx.shape[0]):\n",
        "      hx[i] = x[i][seq_len[i] - 1]\n",
        "\n",
        "    hx = hx.to(device)\n",
        "    hx = self.norm(hx)\n",
        "    out_hx = hx\n",
        "    hx = self.graphconv(hx, edge_index)\n",
        "    hx = self.prelu1(hx)\n",
        "    hx = self.graphconv2(hx, edge_index)\n",
        "    hx = self.prelu1(hx)\n",
        "    hx = self.graphconv2(hx, edge_index)\n",
        "    x_src, x_dst = hx[edge_index[0]], hx[edge_index[1]]\n",
        "    x = torch.cat((x_src, x_dst), dim = 1)\n",
        "    x = self.head_1(x)\n",
        "    probs = 0\n",
        "    return x, probs, out_hx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN + SAGE Conv, берем выходы SAGE Conv"
      ],
      "metadata": {
        "id": "-DICgPUdrZPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphLinkPredictionModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(GraphLinkPredictionModel, self).__init__()\n",
        "\n",
        "    self.rnn = nn.RNN(128, 128, batch_first = True)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "    self.relu = nn.Tanh()\n",
        "    self.norm = nn.BatchNorm1d(128)\n",
        "    self.head_1 = nn.Sequential(nn.Linear(256, 1))\n",
        "    self.sigmoid= nn.Sigmoid()\n",
        "    self.graphconv = SAGEConv(128, 128)\n",
        "    self.graphconv2 = SAGEConv(128, 128)\n",
        "    self.prelu1 = nn.PReLU(128)\n",
        "    self.head_2 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x, seq_len, edge_index):\n",
        "    x, h = self.rnn(x)\n",
        "    hx = torch.zeros(x.shape[0], x.shape[2])\n",
        "    for i in range(hx.shape[0]):\n",
        "      hx[i] = x[i][seq_len[i] - 1]\n",
        "    hx = hx.to(device)\n",
        "    hx = self.norm(hx)\n",
        "    out_hx = hx\n",
        "    hx = self.graphconv(hx, edge_index)\n",
        "    hx = self.prelu1(hx)\n",
        "    hx = self.graphconv2(hx, edge_index)\n",
        "    hx = self.prelu1(hx)\n",
        "    hx = self.graphconv2(hx, edge_index)\n",
        "    x_src, x_dst = hx[edge_index[0]], hx[edge_index[1]]\n",
        "    x = torch.cat((x_src, x_dst), dim = 1)\n",
        "    x = self.head_1(x)\n",
        "    probs = 0\n",
        "    return x, probs, hx"
      ],
      "metadata": {
        "id": "BvEI06sWrNGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Просто RNN"
      ],
      "metadata": {
        "id": "bpANveyTrm11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphLinkPredictionModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(GraphLinkPredictionModel, self).__init__()\n",
        "\n",
        "    self.rnn = nn.RNN(128, 128, batch_first = True)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "    self.relu = nn.Tanh()\n",
        "    self.norm = nn.BatchNorm1d(128)\n",
        "    self.head_1 = nn.Sequential(nn.Linear(256, 1))\n",
        "    self.sigmoid= nn.Sigmoid()\n",
        "    self.graphconv = SAGEConv(128, 128)\n",
        "    self.graphconv2 = SAGEConv(128, 128)\n",
        "    self.prelu1 = nn.PReLU(128)\n",
        "    self.head_2 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x, seq_len, edge_index):\n",
        "    x, h = self.rnn(x)\n",
        "    hx = torch.zeros(x.shape[0], x.shape[2])\n",
        "    for i in range(hx.shape[0]):\n",
        "      hx[i] = x[i][seq_len[i] - 1]\n",
        "    hx = hx.to(device)\n",
        "    hx = self.norm(hx)\n",
        "\n",
        "    x_src, x_dst = hx[edge_index[0]], hx[edge_index[1]]\n",
        "    x = torch.cat((x_src, x_dst), dim = 1)\n",
        "    x = self.head_1(x)\n",
        "    probs = 0\n",
        "    return x, probs, hx"
      ],
      "metadata": {
        "id": "ipm-kUDirh-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:04.213340Z",
          "iopub.status.busy": "2024-05-16T18:59:04.212327Z",
          "iopub.status.idle": "2024-05-16T18:59:10.908319Z",
          "shell.execute_reply": "2024-05-16T18:59:10.907176Z",
          "shell.execute_reply.started": "2024-05-16T18:59:04.213294Z"
        },
        "id": "GHaB159Y6N3e",
        "outputId": "c804e3ff-3953-4b06-8cc6-0c9d936110e3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchmetrics in /home/jupyter/.local/lib/python3.10/site-packages (1.4.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: packaging>17.1 in /kernel/lib/python3.10/site-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/jupyter/.local/lib/python3.10/site-packages (from torchmetrics) (0.11.2)\n",
            "Requirement already satisfied: pretty-errors==1.2.25 in /home/jupyter/.local/lib/python3.10/site-packages (from torchmetrics) (1.2.25)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from pretty-errors==1.2.25->torchmetrics) (0.4.6)\n",
            "Requirement already satisfied: setuptools in /kernel/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.5.0)\n",
            "Requirement already satisfied: typing-extensions in /kernel/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /kernel/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->torchmetrics) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /kernel/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%pip install torchmetrics\n",
        "from torchmetrics.classification import BinaryAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:10.939994Z",
          "iopub.status.busy": "2024-05-16T18:59:10.939092Z",
          "iopub.status.idle": "2024-05-16T18:59:11.077794Z",
          "shell.execute_reply": "2024-05-16T18:59:11.076702Z",
          "shell.execute_reply.started": "2024-05-16T18:59:10.939936Z"
        },
        "tags": [],
        "id": "lAxsWWUKqS4V",
        "outputId": "e0873867-1cfb-4f6a-bb53-e9cd31b3dfa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.reset_peak_memory_stats(device)\n",
        "print(torch.cuda.max_memory_allocated(0) / (1024 ** 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:21.449453Z",
          "iopub.status.busy": "2024-05-16T18:59:21.448252Z",
          "iopub.status.idle": "2024-05-16T19:43:53.825138Z"
        },
        "tags": [],
        "id": "kQeIIum4qS4V",
        "outputId": "24d07fea-2535-4b6a-87d4-5c74c6122073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 0.5328154563903809 Train Accuracy: 0.7150883078575134 Test Accuracy: 0.6756420135498047\n",
            "0.08614587783813477\n",
            "Epoch: 1 Loss: 0.467550128698349 Train Accuracy: 0.739663302898407 Test Accuracy: 0.6740946173667908\n",
            "0.09111881256103516\n",
            "Epoch: 2 Loss: 0.4365590810775757 Train Accuracy: 0.755257248878479 Test Accuracy: 0.6690285801887512\n",
            "0.09484338760375977\n",
            "Epoch: 3 Loss: 0.4140571057796478 Train Accuracy: 0.7670415639877319 Test Accuracy: 0.6642501354217529\n",
            "0.09961557388305664\n",
            "Epoch: 4 Loss: 0.3987140953540802 Train Accuracy: 0.7761774659156799 Test Accuracy: 0.6588885188102722\n",
            "0.10285043716430664\n",
            "Epoch: 5 Loss: 0.38458681106567383 Train Accuracy: 0.7837252616882324 Test Accuracy: 0.6538312435150146\n",
            "0.10593891143798828\n",
            "Epoch: 6 Loss: 0.3747740685939789 Train Accuracy: 0.7901202440261841 Test Accuracy: 0.6488096714019775\n",
            "0.11064863204956055\n",
            "Epoch: 7 Loss: 0.36430999636650085 Train Accuracy: 0.7956680059432983 Test Accuracy: 0.644772469997406\n",
            "0.11440610885620117\n",
            "Epoch: 8 Loss: 0.35635411739349365 Train Accuracy: 0.8005428314208984 Test Accuracy: 0.6410403847694397\n",
            "0.11897420883178711\n",
            "Epoch: 9 Loss: 0.3487343192100525 Train Accuracy: 0.8049153089523315 Test Accuracy: 0.6376956105232239\n",
            "0.39248037338256836\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.reset_peak_memory_stats(device)\n",
        "next_loss_fn = nn.CrossEntropyLoss()\n",
        "model = GraphLinkPredictionModel()\n",
        "link_loss_fn = nn.BCEWithLogitsLoss()\n",
        "accuracy = BinaryAccuracy().to(device)\n",
        "model.to(device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.97, last_epoch=-1)\n",
        "\n",
        "train_user_representations = {}\n",
        "test_user_representations = {}\n",
        "num_epochs = 10\n",
        "accuracies = []\n",
        "test_accuracies = []\n",
        "for i in range(num_epochs):\n",
        "  losses = []\n",
        "  hits_1_scores = []\n",
        "  batch_num = 0\n",
        "  for batch in train_loader:\n",
        "      batch_num += 1\n",
        "      optimizer.zero_grad()\n",
        "      batch = batch.to(device)\n",
        "\n",
        "      link_probs, next_probs, hx = model(batch.x, batch.seq_lens, batch.edge_label_index)\n",
        "      test_link_probs, test_next_probs, test_hx = model(batch.test_features, batch.seq_lens, batch.edge_label_index)\n",
        "      link_probs = link_probs.squeeze()\n",
        "      test_link_probs = test_link_probs.squeeze()\n",
        "\n",
        "      gt = batch.edge_label\n",
        "      link_loss = link_loss_fn(link_probs, gt)\n",
        "      accuracies.append(accuracy(link_probs, gt))\n",
        "      test_accuracies.append(accuracy(test_link_probs, gt))\n",
        "\n",
        "      loss = 1 * link_loss\n",
        "      losses.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      if i == num_epochs - 1:\n",
        "        index = 0\n",
        "        for u in batch.user_ids:\n",
        "          user = u.item()\n",
        "          if user not in train_user_representations.keys():\n",
        "            train_user_representations[user] = (hx[index].detach(), batch.train_labels[index])\n",
        "          if user not in test_user_representations.keys():\n",
        "            test_user_representations[user] = (test_hx[index].detach(), batch.test_labels[index])\n",
        "          index += 1\n",
        "\n",
        "  mean_loss = torch.Tensor(losses).mean(axis=0)\n",
        "  mean_acc = torch.Tensor(accuracies).mean(axis=0).item()\n",
        "  mean_test_acc = torch.Tensor(test_accuracies).mean(axis=0).item()\n",
        "  print(f'Epoch: {i} Loss: {mean_loss.item()} Train Accuracy: {mean_acc} Test Accuracy: {mean_test_acc}')\n",
        "  print(torch.cuda.max_memory_allocated(0) / (1024 ** 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:53:24.955178Z",
          "iopub.status.busy": "2024-05-16T19:53:24.954193Z",
          "iopub.status.idle": "2024-05-16T19:53:24.973574Z",
          "shell.execute_reply": "2024-05-16T19:53:24.972478Z",
          "shell.execute_reply.started": "2024-05-16T19:53:24.955142Z"
        },
        "tags": [],
        "id": "FUEQBocpqS4W",
        "outputId": "8300b231-46f6-4b0d-a263-ba1b52ea2152"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.39248037338256836"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.max_memory_allocated(0) / (1024 ** 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Layer Target training on pre-trained embeddings"
      ],
      "metadata": {
        "id": "lqQoqIfpsy4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:54:13.650147Z",
          "iopub.status.busy": "2024-05-16T19:54:13.649075Z",
          "iopub.status.idle": "2024-05-16T19:54:13.670421Z",
          "shell.execute_reply": "2024-05-16T19:54:13.669277Z",
          "shell.execute_reply.started": "2024-05-16T19:54:13.650102Z"
        },
        "id": "dClBKRy1Evci",
        "tags": []
      },
      "outputs": [],
      "source": [
        "user_train_dataset = UserDataset(train_user_representations)\n",
        "user_test_dataset = UserDataset(test_user_representations)\n",
        "\n",
        "user_train_dataloader = DataLoader(user_train_dataset, batch_size=65, shuffle=True)\n",
        "user_test_dataloader = DataLoader(user_test_dataset, batch_size=65, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:54:15.507656Z",
          "iopub.status.busy": "2024-05-16T19:54:15.506733Z",
          "iopub.status.idle": "2024-05-16T19:54:15.528673Z",
          "shell.execute_reply": "2024-05-16T19:54:15.527435Z",
          "shell.execute_reply.started": "2024-05-16T19:54:15.507618Z"
        },
        "id": "MC1WE3gQX2gl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class TargetModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(TargetModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:54:18.613159Z",
          "iopub.status.busy": "2024-05-16T19:54:18.612196Z",
          "iopub.status.idle": "2024-05-16T19:54:18.646744Z",
          "shell.execute_reply": "2024-05-16T19:54:18.645591Z",
          "shell.execute_reply.started": "2024-05-16T19:54:18.613111Z"
        },
        "id": "zE5_4J9hX2gl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def test(model):\n",
        "  metrics_val = []\n",
        "  model.eval()\n",
        "\n",
        "  for users, vectors, labels in user_test_dataloader:\n",
        "\n",
        "      test_probs = model(vectors.cpu())\n",
        "\n",
        "      test_pred = torch.argmax(test_probs, axis = 1)\n",
        "\n",
        "      test_one_hot = torch.zeros(len(test_probs), num_classes)\n",
        "      test_one_hot[torch.arange(len(test_one_hot)), labels] = 1\n",
        "\n",
        "      hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100,\\\n",
        "      ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100 = get_metrics_(test_probs, labels, test_one_hot)\n",
        "      metrics_val.append([hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100])\n",
        "\n",
        "  mean = torch.Tensor(metrics_val).mean(axis=0)\n",
        "  test_hits1, test_hits5, test_hits10, test_hits20, test_hits50, test_hits100, test_map1, test_map5, test_map10, test_map20, test_map50, test_map100, \\\n",
        "  test_ndcg1, test_ndcg5,test_ndcg10, test_ndcg20, test_ndcg50, test_ndcg100 = mean\n",
        "\n",
        "  return test_hits1, test_hits5, test_hits10, test_hits20, test_hits50, test_hits100, test_map1, test_map5, test_map10, test_map20, test_map50, test_map100,\\\n",
        "  test_ndcg1, test_ndcg5,test_ndcg10, test_ndcg20, test_ndcg50, test_ndcg100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:54:23.590631Z",
          "iopub.status.busy": "2024-05-16T19:54:23.589544Z",
          "iopub.status.idle": "2024-05-16T19:54:23.607657Z",
          "shell.execute_reply": "2024-05-16T19:54:23.606547Z",
          "shell.execute_reply.started": "2024-05-16T19:54:23.590591Z"
        },
        "id": "wKvFXAjrojlA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def middle_test(f):\n",
        "  hits_1 = []\n",
        "  for users, vectors, labels in user_test_dataloader:\n",
        "\n",
        "    test_probs = model(vectors.cpu())\n",
        "\n",
        "    test_pred = torch.argmax(test_probs, axis = 1)\n",
        "\n",
        "    test_one_hot = torch.zeros(len(test_probs), num_classes)\n",
        "    test_one_hot[torch.arange(len(test_one_hot)), labels] = 1\n",
        "    hits_1.append(top_k_accuracy_score(labels, test_probs.cpu().detach().numpy(), k=1, labels = classes))\n",
        "  print(f'Hits@1: {torch.mean(torch.Tensor(hits_1))}')\n",
        "  f.write(f'Hits@1: {torch.mean(torch.Tensor(hits_1))}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:54:24.861020Z",
          "iopub.status.busy": "2024-05-16T19:54:24.859896Z",
          "iopub.status.idle": "2024-05-16T19:54:24.879445Z",
          "shell.execute_reply": "2024-05-16T19:54:24.878303Z",
          "shell.execute_reply.started": "2024-05-16T19:54:24.860979Z"
        },
        "tags": [],
        "id": "QIFC_pn9qS4Z",
        "outputId": "1b789164-894f-4617-c1b9-6b3cd719b761"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.33942604064941406"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.reset_peak_memory_stats(device)\n",
        "torch.cuda.max_memory_allocated(0) / (1024 ** 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-16T19:54:55.906680Z",
          "iopub.status.busy": "2024-05-16T19:54:55.905526Z",
          "iopub.status.idle": "2024-05-16T19:59:23.450655Z",
          "shell.execute_reply": "2024-05-16T19:59:23.449416Z",
          "shell.execute_reply.started": "2024-05-16T19:54:55.906631Z"
        },
        "id": "C9fUIXyGX2gl",
        "outputId": "856cbff1-3188-4a9a-8b5b-a9677f994c68",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 8.157064437866211\n",
            "0.33942604064941406\n",
            "Epoch: 1 Loss: 7.882716655731201\n",
            "0.33942604064941406\n",
            "Epoch: 2 Loss: 7.633568286895752\n",
            "0.33942604064941406\n",
            "Epoch: 3 Loss: 7.400608539581299\n",
            "0.33942604064941406\n",
            "Epoch: 4 Loss: 7.180976867675781\n",
            "0.33942604064941406\n",
            "Epoch: 5 Loss: 6.97373628616333\n",
            "0.33942604064941406\n",
            "Epoch: 6 Loss: 6.778742790222168\n",
            "0.33942604064941406\n",
            "Epoch: 7 Loss: 6.596052646636963\n",
            "0.33942604064941406\n",
            "Epoch: 8 Loss: 6.425450801849365\n",
            "0.33942604064941406\n",
            "Epoch: 9 Loss: 6.266213417053223\n",
            "0.33942604064941406\n",
            "Epoch: 10 Loss: 6.117584228515625\n",
            "0.33942604064941406\n",
            "Epoch: 11 Loss: 5.978617191314697\n",
            "0.33942604064941406\n",
            "Epoch: 12 Loss: 5.848659515380859\n",
            "0.33942604064941406\n",
            "Epoch: 13 Loss: 5.726806640625\n",
            "0.33942604064941406\n",
            "Epoch: 14 Loss: 5.6122918128967285\n",
            "0.33942604064941406\n",
            "Epoch: 15 Loss: 5.5044684410095215\n",
            "0.33942604064941406\n",
            "Epoch: 16 Loss: 5.402859210968018\n",
            "0.33942604064941406\n",
            "Epoch: 17 Loss: 5.306805610656738\n",
            "0.33942604064941406\n",
            "Epoch: 18 Loss: 5.2158660888671875\n",
            "0.33942604064941406\n",
            "Epoch: 19 Loss: 5.129671096801758\n",
            "0.33942604064941406\n",
            "Epoch: 20 Loss: 5.047783851623535\n",
            "0.33942604064941406\n",
            "Epoch: 21 Loss: 4.969928741455078\n",
            "0.33942604064941406\n",
            "Epoch: 22 Loss: 4.895761966705322\n",
            "0.33942604064941406\n",
            "Epoch: 23 Loss: 4.825008869171143\n",
            "0.33942604064941406\n",
            "Epoch: 24 Loss: 4.757460594177246\n",
            "0.33942604064941406\n",
            "Epoch: 25 Loss: 4.692849159240723\n",
            "0.33942604064941406\n",
            "Epoch: 26 Loss: 4.631018161773682\n",
            "0.33942604064941406\n",
            "Epoch: 27 Loss: 4.571747303009033\n",
            "0.33942604064941406\n",
            "Epoch: 28 Loss: 4.514877796173096\n",
            "0.33942604064941406\n",
            "Epoch: 29 Loss: 4.460244655609131\n",
            "0.33942604064941406\n",
            "Epoch: 30 Loss: 4.407712936401367\n",
            "0.33942604064941406\n",
            "Epoch: 31 Loss: 4.357148170471191\n",
            "0.33942604064941406\n",
            "Epoch: 32 Loss: 4.308427810668945\n",
            "0.33942604064941406\n",
            "Epoch: 33 Loss: 4.2614240646362305\n",
            "0.33942604064941406\n",
            "Epoch: 34 Loss: 4.216088771820068\n",
            "0.33942604064941406\n",
            "Epoch: 35 Loss: 4.172307014465332\n",
            "0.33942604064941406\n",
            "Epoch: 36 Loss: 4.129955768585205\n",
            "0.33942604064941406\n",
            "Epoch: 37 Loss: 4.088997840881348\n",
            "0.33942604064941406\n",
            "Epoch: 38 Loss: 4.0493645668029785\n",
            "0.33942604064941406\n",
            "Epoch: 39 Loss: 4.010937213897705\n",
            "0.33942604064941406\n",
            "Epoch: 40 Loss: 3.9736876487731934\n",
            "0.33942604064941406\n",
            "Epoch: 41 Loss: 3.93753981590271\n",
            "0.33942604064941406\n",
            "Epoch: 42 Loss: 3.9024627208709717\n",
            "0.33942604064941406\n",
            "Epoch: 43 Loss: 3.8683953285217285\n",
            "0.33942604064941406\n",
            "Epoch: 44 Loss: 3.8352890014648438\n",
            "0.33942604064941406\n",
            "Epoch: 45 Loss: 3.8030946254730225\n",
            "0.33942604064941406\n",
            "Epoch: 46 Loss: 3.771768808364868\n",
            "0.33942604064941406\n",
            "Epoch: 47 Loss: 3.741279363632202\n",
            "0.33942604064941406\n",
            "Epoch: 48 Loss: 3.7115960121154785\n",
            "0.33942604064941406\n",
            "Epoch: 49 Loss: 3.682676076889038\n",
            "0.33942604064941406\n",
            "Epoch: 50 Loss: 3.654479503631592\n",
            "0.33942604064941406\n",
            "Epoch: 51 Loss: 3.6269774436950684\n",
            "0.33942604064941406\n",
            "Epoch: 52 Loss: 3.600154399871826\n",
            "0.33942604064941406\n",
            "Epoch: 53 Loss: 3.5739645957946777\n",
            "0.33942604064941406\n",
            "Epoch: 54 Loss: 3.548402786254883\n",
            "0.33942604064941406\n",
            "Epoch: 55 Loss: 3.523439645767212\n",
            "0.33942604064941406\n",
            "Epoch: 56 Loss: 3.499042272567749\n",
            "0.33942604064941406\n",
            "Epoch: 57 Loss: 3.4751904010772705\n",
            "0.33942604064941406\n",
            "Epoch: 58 Loss: 3.451880931854248\n",
            "0.33942604064941406\n",
            "Epoch: 59 Loss: 3.4290809631347656\n",
            "0.33942604064941406\n",
            "Epoch: 60 Loss: 3.4067795276641846\n",
            "0.33942604064941406\n",
            "Epoch: 61 Loss: 3.3849446773529053\n",
            "0.33942604064941406\n",
            "Epoch: 62 Loss: 3.363579511642456\n",
            "0.33942604064941406\n",
            "Epoch: 63 Loss: 3.3426554203033447\n",
            "0.33942604064941406\n",
            "Epoch: 64 Loss: 3.3221638202667236\n",
            "0.33942604064941406\n",
            "Epoch: 65 Loss: 3.302072525024414\n",
            "0.33942604064941406\n",
            "Epoch: 66 Loss: 3.2823903560638428\n",
            "0.33942604064941406\n",
            "Epoch: 67 Loss: 3.2630863189697266\n",
            "0.33942604064941406\n",
            "Epoch: 68 Loss: 3.2441539764404297\n",
            "0.33942604064941406\n",
            "Epoch: 69 Loss: 3.2255938053131104\n",
            "0.33942604064941406\n",
            "Epoch: 70 Loss: 3.207381010055542\n",
            "0.33942604064941406\n",
            "Epoch: 71 Loss: 3.1895151138305664\n",
            "0.33942604064941406\n",
            "Epoch: 72 Loss: 3.17197585105896\n",
            "0.33942604064941406\n",
            "Epoch: 73 Loss: 3.154756546020508\n",
            "0.33942604064941406\n",
            "Epoch: 74 Loss: 3.1378591060638428\n",
            "0.33942604064941406\n",
            "Epoch: 75 Loss: 3.12125825881958\n",
            "0.33942604064941406\n",
            "Epoch: 76 Loss: 3.1049482822418213\n",
            "0.33942604064941406\n",
            "Epoch: 77 Loss: 3.0889246463775635\n",
            "0.33942604064941406\n",
            "Epoch: 78 Loss: 3.0731770992279053\n",
            "0.33942604064941406\n",
            "Epoch: 79 Loss: 3.0577008724212646\n",
            "0.33942604064941406\n",
            "Epoch: 80 Loss: 3.0424890518188477\n",
            "0.33942604064941406\n",
            "Epoch: 81 Loss: 3.027529001235962\n",
            "0.33942604064941406\n",
            "Epoch: 82 Loss: 3.012817144393921\n",
            "0.33942604064941406\n",
            "Epoch: 83 Loss: 2.998354911804199\n",
            "0.33942604064941406\n",
            "Epoch: 84 Loss: 2.9841225147247314\n",
            "0.33942604064941406\n",
            "Epoch: 85 Loss: 2.970118522644043\n",
            "0.33942604064941406\n",
            "Epoch: 86 Loss: 2.956338405609131\n",
            "0.33942604064941406\n",
            "Epoch: 87 Loss: 2.942776918411255\n",
            "0.33942604064941406\n",
            "Epoch: 88 Loss: 2.9294283390045166\n",
            "0.33942604064941406\n",
            "Epoch: 89 Loss: 2.9162847995758057\n",
            "0.33942604064941406\n",
            "Epoch: 90 Loss: 2.9033405780792236\n",
            "0.33942604064941406\n",
            "Epoch: 91 Loss: 2.890594959259033\n",
            "0.33942604064941406\n",
            "Epoch: 92 Loss: 2.878040313720703\n",
            "0.33942604064941406\n",
            "Epoch: 93 Loss: 2.8656721115112305\n",
            "0.33942604064941406\n",
            "Epoch: 94 Loss: 2.8534884452819824\n",
            "0.33942604064941406\n",
            "Epoch: 95 Loss: 2.841475248336792\n",
            "0.33942604064941406\n",
            "Epoch: 96 Loss: 2.829643726348877\n",
            "0.33942604064941406\n",
            "Epoch: 97 Loss: 2.8179712295532227\n",
            "0.33942604064941406\n",
            "Epoch: 98 Loss: 2.806471347808838\n",
            "0.33942604064941406\n",
            "Epoch: 99 Loss: 2.795130491256714\n",
            "0.33942604064941406\n",
            "Epoch: 100 Loss: 2.783954381942749\n",
            "0.33942604064941406\n",
            "Epoch: 101 Loss: 2.77292537689209\n",
            "0.33942604064941406\n",
            "Epoch: 102 Loss: 2.7620530128479004\n",
            "0.33942604064941406\n",
            "Epoch: 103 Loss: 2.7513251304626465\n",
            "0.33942604064941406\n",
            "Epoch: 104 Loss: 2.740748643875122\n",
            "0.33942604064941406\n",
            "Epoch: 105 Loss: 2.730311632156372\n",
            "0.33942604064941406\n",
            "Epoch: 106 Loss: 2.7200064659118652\n",
            "0.33942604064941406\n",
            "Epoch: 107 Loss: 2.7098400592803955\n",
            "0.33942604064941406\n",
            "Epoch: 108 Loss: 2.6998062133789062\n",
            "0.33942604064941406\n",
            "Epoch: 109 Loss: 2.6899054050445557\n",
            "0.33942604064941406\n",
            "Epoch: 110 Loss: 2.6801235675811768\n",
            "0.33942604064941406\n",
            "Epoch: 111 Loss: 2.670468807220459\n",
            "0.33942604064941406\n",
            "Epoch: 112 Loss: 2.6609408855438232\n",
            "0.33942604064941406\n",
            "Epoch: 113 Loss: 2.651529312133789\n",
            "0.33942604064941406\n",
            "Epoch: 114 Loss: 2.6422290802001953\n",
            "0.33942604064941406\n",
            "Epoch: 115 Loss: 2.6330480575561523\n",
            "0.33942604064941406\n",
            "Epoch: 116 Loss: 2.623978614807129\n",
            "0.33942604064941406\n",
            "Epoch: 117 Loss: 2.615013837814331\n",
            "0.33942604064941406\n",
            "Epoch: 118 Loss: 2.606163740158081\n",
            "0.33942604064941406\n",
            "Epoch: 119 Loss: 2.597416639328003\n",
            "0.33942604064941406\n",
            "Epoch: 120 Loss: 2.588775873184204\n",
            "0.33942604064941406\n",
            "Epoch: 121 Loss: 2.5802319049835205\n",
            "0.33942604064941406\n",
            "Epoch: 122 Loss: 2.5717878341674805\n",
            "0.33942604064941406\n",
            "Epoch: 123 Loss: 2.5634422302246094\n",
            "0.33942604064941406\n",
            "Epoch: 124 Loss: 2.555192470550537\n",
            "0.33942604064941406\n",
            "Epoch: 125 Loss: 2.5470378398895264\n",
            "0.33942604064941406\n",
            "Epoch: 126 Loss: 2.538973808288574\n",
            "0.33942604064941406\n",
            "Epoch: 127 Loss: 2.531003475189209\n",
            "0.33942604064941406\n",
            "Epoch: 128 Loss: 2.523120641708374\n",
            "0.33942604064941406\n",
            "Epoch: 129 Loss: 2.51532244682312\n",
            "0.33942604064941406\n",
            "Epoch: 130 Loss: 2.50761342048645\n",
            "0.33942604064941406\n",
            "Epoch: 131 Loss: 2.4999897480010986\n",
            "0.33942604064941406\n",
            "Epoch: 132 Loss: 2.492448329925537\n",
            "0.33942604064941406\n",
            "Epoch: 133 Loss: 2.484987258911133\n",
            "0.33942604064941406\n",
            "Epoch: 134 Loss: 2.4776058197021484\n",
            "0.33942604064941406\n",
            "Epoch: 135 Loss: 2.4703028202056885\n",
            "0.33942604064941406\n",
            "Epoch: 136 Loss: 2.46307635307312\n",
            "0.33942604064941406\n",
            "Epoch: 137 Loss: 2.455927610397339\n",
            "0.33942604064941406\n",
            "Epoch: 138 Loss: 2.448852777481079\n",
            "0.33942604064941406\n",
            "Epoch: 139 Loss: 2.441850185394287\n",
            "0.33942604064941406\n",
            "Epoch: 140 Loss: 2.434917449951172\n",
            "0.33942604064941406\n",
            "Epoch: 141 Loss: 2.428056240081787\n",
            "0.33942604064941406\n",
            "Epoch: 142 Loss: 2.421262741088867\n",
            "0.33942604064941406\n",
            "Epoch: 143 Loss: 2.4145426750183105\n",
            "0.33942604064941406\n",
            "Epoch: 144 Loss: 2.4078874588012695\n",
            "0.33942604064941406\n",
            "Epoch: 145 Loss: 2.401294469833374\n",
            "0.33942604064941406\n",
            "Epoch: 146 Loss: 2.3947691917419434\n",
            "0.33942604064941406\n",
            "Epoch: 147 Loss: 2.388310432434082\n",
            "0.33942604064941406\n",
            "Epoch: 148 Loss: 2.381913900375366\n",
            "0.33942604064941406\n",
            "Epoch: 149 Loss: 2.3755767345428467\n",
            "0.33942604064941406\n",
            "Epoch: 150 Loss: 2.3692996501922607\n",
            "0.33942604064941406\n",
            "Epoch: 151 Loss: 2.3630828857421875\n",
            "0.33942604064941406\n",
            "Epoch: 152 Loss: 2.356928586959839\n",
            "0.33942604064941406\n",
            "Epoch: 153 Loss: 2.3508312702178955\n",
            "0.33942604064941406\n",
            "Epoch: 154 Loss: 2.344789981842041\n",
            "0.33942604064941406\n",
            "Epoch: 155 Loss: 2.33880352973938\n",
            "0.33942604064941406\n",
            "Epoch: 156 Loss: 2.3328731060028076\n",
            "0.33942604064941406\n",
            "Epoch: 157 Loss: 2.326996088027954\n",
            "0.33942604064941406\n",
            "Epoch: 158 Loss: 2.3211777210235596\n",
            "0.33942604064941406\n",
            "Epoch: 159 Loss: 2.3154120445251465\n",
            "0.33942604064941406\n",
            "Epoch: 160 Loss: 2.3096964359283447\n",
            "0.33942604064941406\n",
            "Epoch: 161 Loss: 2.304034471511841\n",
            "0.33942604064941406\n",
            "Epoch: 162 Loss: 2.298424005508423\n",
            "0.33942604064941406\n",
            "Epoch: 163 Loss: 2.2928600311279297\n",
            "0.33942604064941406\n",
            "Epoch: 164 Loss: 2.287348985671997\n",
            "0.33942604064941406\n",
            "Epoch: 165 Loss: 2.2818856239318848\n",
            "0.33942604064941406\n",
            "Epoch: 166 Loss: 2.276468276977539\n",
            "0.33942604064941406\n",
            "Epoch: 167 Loss: 2.271096706390381\n",
            "0.33942604064941406\n",
            "Epoch: 168 Loss: 2.2657742500305176\n",
            "0.33942604064941406\n",
            "Epoch: 169 Loss: 2.260495901107788\n",
            "0.33942604064941406\n",
            "Epoch: 170 Loss: 2.255262851715088\n",
            "0.33942604064941406\n",
            "Epoch: 171 Loss: 2.250072717666626\n",
            "0.33942604064941406\n",
            "Epoch: 172 Loss: 2.244929075241089\n",
            "0.33942604064941406\n",
            "Epoch: 173 Loss: 2.2398293018341064\n",
            "0.33942604064941406\n",
            "Epoch: 174 Loss: 2.2347710132598877\n",
            "0.33942604064941406\n",
            "Epoch: 175 Loss: 2.2297539710998535\n",
            "0.33942604064941406\n",
            "Epoch: 176 Loss: 2.224778652191162\n",
            "0.33942604064941406\n",
            "Epoch: 177 Loss: 2.219846487045288\n",
            "0.33942604064941406\n",
            "Epoch: 178 Loss: 2.2149529457092285\n",
            "0.33942604064941406\n",
            "Epoch: 179 Loss: 2.210101366043091\n",
            "0.33942604064941406\n",
            "Epoch: 180 Loss: 2.205286741256714\n",
            "0.33942604064941406\n",
            "Epoch: 181 Loss: 2.200512409210205\n",
            "0.33942604064941406\n",
            "Epoch: 182 Loss: 2.1957743167877197\n",
            "0.33942604064941406\n",
            "Epoch: 183 Loss: 2.1910746097564697\n",
            "0.33942604064941406\n",
            "Epoch: 184 Loss: 2.1864144802093506\n",
            "0.33942604064941406\n",
            "Epoch: 185 Loss: 2.1817870140075684\n",
            "0.33942604064941406\n",
            "Epoch: 186 Loss: 2.1771974563598633\n",
            "0.33942604064941406\n",
            "Epoch: 187 Loss: 2.172644853591919\n",
            "0.33942604064941406\n",
            "Epoch: 188 Loss: 2.1681270599365234\n",
            "0.33942604064941406\n",
            "Epoch: 189 Loss: 2.163642406463623\n",
            "0.33942604064941406\n",
            "Epoch: 190 Loss: 2.1591923236846924\n",
            "0.33942604064941406\n",
            "Epoch: 191 Loss: 2.154780864715576\n",
            "0.33942604064941406\n",
            "Epoch: 192 Loss: 2.1503994464874268\n",
            "0.33942604064941406\n",
            "Epoch: 193 Loss: 2.146050214767456\n",
            "0.33942604064941406\n",
            "Epoch: 194 Loss: 2.1417365074157715\n",
            "0.33942604064941406\n",
            "Epoch: 195 Loss: 2.137453556060791\n",
            "0.33942604064941406\n",
            "Epoch: 196 Loss: 2.1332011222839355\n",
            "0.33942604064941406\n",
            "Epoch: 197 Loss: 2.128981590270996\n",
            "0.33942604064941406\n",
            "Epoch: 198 Loss: 2.1247963905334473\n",
            "0.33942604064941406\n",
            "Epoch: 199 Loss: 2.120640277862549\n",
            "0.33942604064941406\n"
          ]
        }
      ],
      "source": [
        "f = open('linear_layer_target_training_3883.txt', 'w+')\n",
        "torch.cuda.reset_peak_memory_stats(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model  = TargetModel()\n",
        "\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.97, last_epoch=-1)\n",
        "losses = []\n",
        "hits_1 = []\n",
        "\n",
        "for i in range(200):\n",
        "  for users, vectors, labels in user_train_dataloader:\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      probs = model(vectors.cpu())\n",
        "      pred = torch.argmax(probs, axis = 1)\n",
        "      one_hot = torch.zeros(len(probs), num_classes)\n",
        "      one_hot[torch.arange(len(one_hot)), labels] = 1\n",
        "      loss = loss_fn(probs, one_hot)\n",
        "      losses.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  print(f'Epoch: {i} Loss: {torch.mean(torch.Tensor(losses))}')\n",
        "  f.write(f'Epoch: {i} Loss: {torch.mean(torch.Tensor(losses))}')\n",
        "  print(torch.cuda.max_memory_allocated(0) / (1024 ** 3))\n",
        "  middle_test(f)\n",
        "hits1, hits5, hits10, hits20, hits50, hits100, map1,map5, map10, map20, map50, map100, \\\n",
        "ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100 = test(model)\n",
        "print_metrics(hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100)\n",
        "write_to_file(f, hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:59:23.453072Z",
          "iopub.status.busy": "2024-05-16T19:59:23.452335Z",
          "iopub.status.idle": "2024-05-16T19:59:23.469254Z",
          "shell.execute_reply": "2024-05-16T19:59:23.468138Z",
          "shell.execute_reply.started": "2024-05-16T19:59:23.453021Z"
        },
        "tags": [],
        "id": "Nwl3u7m5qS4Z",
        "outputId": "72921751-de4a-4679-f0f4-d719d97653f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.33942604064941406"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.max_memory_allocated(0) / (1024 ** 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2bf5MyhwGNf"
      },
      "source": [
        "### RNN Target training with Concatenation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:59:33.261625Z",
          "iopub.status.busy": "2024-05-16T19:59:33.260803Z",
          "iopub.status.idle": "2024-05-16T19:59:37.308413Z",
          "shell.execute_reply": "2024-05-16T19:59:37.307153Z",
          "shell.execute_reply.started": "2024-05-16T19:59:33.261590Z"
        },
        "id": "UdYvqvYFEjF3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "users_list = load_dataset_timestamp(20001, 128, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:59:37.311104Z",
          "iopub.status.busy": "2024-05-16T19:59:37.310143Z",
          "iopub.status.idle": "2024-05-16T19:59:37.331106Z",
          "shell.execute_reply": "2024-05-16T19:59:37.330142Z",
          "shell.execute_reply.started": "2024-05-16T19:59:37.311057Z"
        },
        "id": "9UT5bJMxwKkS",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import random\n",
        "class UserInfoDataset():\n",
        "  def __init__(self, data, max_len, train_user_representations, test_user_representations, coeff):\n",
        "    self.data = data\n",
        "    self.max_len = max_len\n",
        "    self.train_user_representations = train_user_representations\n",
        "    self.test_user_representations = test_user_representations\n",
        "    self.coeff = coeff\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    user = self.data[idx]\n",
        "    seq_len = user['seq_len']\n",
        "    seq_len = len(user['train_act_seq'])\n",
        "    indexes = np.arange(0, seq_len)\n",
        "    if seq_len - self.coeff > 0:\n",
        "      seq_len = seq_len - self.coeff\n",
        "    random_indexes = random.sample(list(indexes), seq_len)\n",
        "    user['train_act_seq'] = np.array(user['train_act_seq'])\n",
        "    user['train_act_seq'] = user['train_act_seq'][sorted(random_indexes)]\n",
        "    user['test_act_seq'] = np.array(user['test_act_seq'])\n",
        "    user['test_act_seq'] = user['test_act_seq'][sorted(random_indexes)]\n",
        "    user['train_time_seq'] = np.array(user['train_time_seq'])\n",
        "    user['train_time_seq'] = user['train_time_seq'][sorted(random_indexes)]\n",
        "    user['test_time_seq'] = np.array(user['test_time_seq'])\n",
        "    user['test_time_seq'] = user['test_time_seq'][sorted(random_indexes)]\n",
        "\n",
        "    tr_act_seq = np.zeros((self.max_len,)).astype('int32')\n",
        "    tr_act_seq[:seq_len] = np.array(user['train_act_seq'])\n",
        "    tr_act_seq = np.transpose(tr_act_seq)\n",
        "\n",
        "    tr_time_seq = np.zeros((self.max_len,)).astype('int32')\n",
        "    tr_time_seq[:seq_len] = user['train_time_seq']\n",
        "    tr_time_seq = np.transpose(tr_time_seq)\n",
        "\n",
        "    t_act_seq = np.zeros((self.max_len, )).astype('int32')\n",
        "    t_act_seq[:seq_len] = user['test_act_seq']\n",
        "    t_act_seq = np.transpose(t_act_seq)\n",
        "\n",
        "    t_time_seq = np.zeros((self.max_len, )).astype('int32')\n",
        "    t_time_seq[:seq_len] = user['test_time_seq']\n",
        "    t_time_seq = np.transpose(t_time_seq)\n",
        "\n",
        "    if idx not in self.train_user_representations.keys():\n",
        "      self.train_user_representations[idx] = (torch.zeros(size=(128,)), torch.tensor(0))\n",
        "      self.test_user_representations[idx] = (torch.zeros(size=(128,)), torch.tensor(0))\n",
        "\n",
        "\n",
        "    return user['user'], tr_act_seq, \\\n",
        "    tr_time_seq, user['train_act_label'], \\\n",
        "    user['train_time_label'], t_act_seq, \\\n",
        "    t_time_seq, user['test_act_label'], \\\n",
        "    user['test_time_label'], seq_len, self.train_user_representations[idx][0].cpu(), self.test_user_representations[idx][0].cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corruption Коэффициент для экспериментов на проверку устойчивости"
      ],
      "metadata": {
        "id": "imV_YyNyt1uP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:59:37.333340Z",
          "iopub.status.busy": "2024-05-16T19:59:37.332758Z",
          "iopub.status.idle": "2024-05-16T19:59:37.345522Z",
          "shell.execute_reply": "2024-05-16T19:59:37.344254Z",
          "shell.execute_reply.started": "2024-05-16T19:59:37.333293Z"
        },
        "tags": [],
        "id": "ufHSGPpKqS4a"
      },
      "outputs": [],
      "source": [
        "coeff = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:59:39.805233Z",
          "iopub.status.busy": "2024-05-16T19:59:39.804291Z",
          "iopub.status.idle": "2024-05-16T19:59:39.851015Z",
          "shell.execute_reply": "2024-05-16T19:59:39.849860Z",
          "shell.execute_reply.started": "2024-05-16T19:59:39.805182Z"
        },
        "tags": [],
        "id": "9yIxH2sEqS4a"
      },
      "outputs": [],
      "source": [
        "user_dataset = UserInfoDataset(users_list, 30, train_user_representations, test_user_representations, coeff)\n",
        "user_dataloader = DataLoader(user_dataset, batch_size = 64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Конкатенация с предобученным эмбеддингом"
      ],
      "metadata": {
        "id": "aAuVOFbJuHZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:59:41.164291Z",
          "iopub.status.busy": "2024-05-16T19:59:41.163239Z",
          "iopub.status.idle": "2024-05-16T19:59:41.181138Z",
          "shell.execute_reply": "2024-05-16T19:59:41.180128Z",
          "shell.execute_reply.started": "2024-05-16T19:59:41.164219Z"
        },
        "id": "Qo0UCpaRyu0z",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class RNNTargetModel(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(RNNTargetModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(256, num_classes)\n",
        "    self.rnn = nn.RNN(128, 128, batch_first = True)\n",
        "    self.norm = nn.BatchNorm1d(128)\n",
        "    self.reduce_dim = nn.Linear(128, 128)\n",
        "\n",
        "  def forward(self, x, repr, seq_len):\n",
        "    x, h = self.rnn(x)\n",
        "    hx = torch.zeros(x.shape[0], x.shape[2])\n",
        "    for i in range(hx.shape[0]):\n",
        "      hx[i] = x[i][seq_len[i] - 1]\n",
        "    hx = hx.to(device)\n",
        "    hx = self.norm(hx)\n",
        "    hx = torch.cat([hx, repr], dim= 1)\n",
        "    x = self.fc1(hx)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Конкатенация со случайно сгенерированным эмбеддингом"
      ],
      "metadata": {
        "id": "an662c-8uRbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNTargetModel(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(RNNTargetModel, self).__init__()\n",
        "    self.fc1 = nn.Linear(256, num_classes)\n",
        "    self.rnn = nn.RNN(128, 128, batch_first = True)\n",
        "    self.norm = nn.BatchNorm1d(128)\n",
        "    self.reduce_dim = nn.Linear(128, 128)\n",
        "\n",
        "  def forward(self, x, repr, seq_len):\n",
        "    x, h = self.rnn(x)\n",
        "    hx = torch.zeros(x.shape[0], x.shape[2])\n",
        "    for i in range(hx.shape[0]):\n",
        "      hx[i] = x[i][seq_len[i] - 1]\n",
        "    hx = hx.to(device)\n",
        "    hx = self.norm(hx)\n",
        "    repr = torch.rand((len(x), 128))\n",
        "    hx = torch.cat([hx, repr], dim= 1)\n",
        "    x = self.fc1(hx)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ENNFcKYNuMiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:59:43.581677Z",
          "iopub.status.busy": "2024-05-16T19:59:43.580692Z",
          "iopub.status.idle": "2024-05-16T19:59:43.603571Z",
          "shell.execute_reply": "2024-05-16T19:59:43.602460Z",
          "shell.execute_reply.started": "2024-05-16T19:59:43.581642Z"
        },
        "id": "tlkvda7NYagQ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def rnn_target_test(model):\n",
        "  metrics_val = []\n",
        "  model.eval()\n",
        "  index = 0\n",
        "\n",
        "  for user, train_input, train_time, train_label, train_time_label, test_input, test_time, test_label, test_time_label, seq_len, train_repr, test_repr in user_dataloader:\n",
        "\n",
        "      test_comb_input = np.concatenate([np.expand_dims(test_input, axis=-1),\n",
        "                                                np.expand_dims(test_time, axis=-1)], axis=2)\n",
        "      model_input = test_comb_input\n",
        "      model_output = test_label\n",
        "      test_rnn_input_emb = item_emb[model_input[:, :, 0]]\n",
        "      test_probs = model(test_rnn_input_emb.cuda(), test_repr, seq_len)\n",
        "\n",
        "      test_pred = torch.argmax(test_probs, axis = 1)\n",
        "\n",
        "      test_one_hot = torch.zeros(len(test_probs), num_classes)\n",
        "      test_one_hot[torch.arange(len(test_one_hot)), test_label] = 1\n",
        "      loss = loss_fn(test_probs, test_one_hot.cuda())\n",
        "\n",
        "      hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, \\\n",
        "      ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100 = get_metrics_(test_probs, test_label, test_one_hot)\n",
        "\n",
        "      metrics_val.append([hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100])\n",
        "\n",
        "\n",
        "  mean = torch.Tensor(metrics_val).mean(axis=0)\n",
        "  test_hits1, test_hits5, test_hits10, test_hits20, test_hits50, test_hits100, \\\n",
        "  test_map1, test_map5, test_map10, test_map20, test_map50, test_map100, test_ndcg1, test_ndcg5, test_ndcg10, test_ndcg20, test_ndcg50, test_ndcg100 = mean\n",
        "  return test_hits1, test_hits5, test_hits10, test_hits20, test_hits50, test_hits100, test_map1, test_map5, test_map10, test_map20, test_map50, test_map100,\\\n",
        "  test_ndcg1, test_ndcg5, test_ndcg10, test_ndcg20, test_ndcg50, test_ndcg100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T19:59:44.111230Z",
          "iopub.status.busy": "2024-05-16T19:59:44.110218Z",
          "iopub.status.idle": "2024-05-16T19:59:44.126598Z",
          "shell.execute_reply": "2024-05-16T19:59:44.125485Z",
          "shell.execute_reply.started": "2024-05-16T19:59:44.111190Z"
        },
        "id": "LAJPPO80yAK8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def write_to_file(f, hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100):\n",
        "    f.write(f'hits@1: {hits1:.6f}, hits@5: {hits5:.6f}, hits@10: {hits10:.6f}, hits@20: {hits20:.6f}\\n')\n",
        "    f.write(f'hits@50: {hits50:.6f}, hits@100: {hits100:.6f}\\n')\n",
        "    f.write(f'map@1: {map1:.6f}, map@5: {map5:.6f}, map@10: {map10:.6f}, map@20: {map20:.6f}\\n')\n",
        "    f.write(f'map@50: {map50:.6f}, map@100: {map100:.6f}\\n')\n",
        "    f.write(f'ndcg@1: {ndcg1:.6f}, ndcg@5: {ndcg5:.6f}, ndcg@10: {ndcg10:.6f}, ndcg@20: {ndcg20:.6f}\\n')\n",
        "    f.write(f'ndcg@50: {ndcg50:.6f}, ndcg@100: {ndcg100:.6f}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T20:00:15.715775Z",
          "iopub.status.busy": "2024-05-16T20:00:15.714862Z",
          "iopub.status.idle": "2024-05-16T20:00:15.742399Z",
          "shell.execute_reply": "2024-05-16T20:00:15.741236Z",
          "shell.execute_reply.started": "2024-05-16T20:00:15.715735Z"
        },
        "id": "erNoQV51qS4b",
        "outputId": "6299bbd4-5728-48e8-900a-9d0d21caba62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3348393440246582\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.reset_peak_memory_stats(device)\n",
        "print(torch.cuda.max_memory_allocated(0) / (1024 ** 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-05-16T20:00:23.979637Z",
          "iopub.status.busy": "2024-05-16T20:00:23.978479Z",
          "iopub.status.idle": "2024-05-16T20:06:00.426223Z",
          "shell.execute_reply": "2024-05-16T20:06:00.424935Z",
          "shell.execute_reply.started": "2024-05-16T20:00:23.979563Z"
        },
        "id": "V9KvC7SUxkfW",
        "outputId": "06103dce-efda-4943-e9e1-33fae86cd13e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 7.748237133026123, Val loss: 7.765230178833008 Hits@1: 0.08204448223114014\n",
            "1.8501653671264648\n",
            "Epoch: 1 Loss: 6.409521102905273, Val loss: 6.5093865394592285 Hits@1: 0.2646901309490204\n",
            "1.8501653671264648\n",
            "Epoch: 2 Loss: 5.349963188171387, Val loss: 5.513329029083252 Hits@1: 0.3352590501308441\n",
            "1.8501653671264648\n",
            "Epoch: 3 Loss: 4.551754474639893, Val loss: 4.765737533569336 Hits@1: 0.39165517687797546\n",
            "1.8501653671264648\n",
            "Epoch: 4 Loss: 3.9575483798980713, Val loss: 4.2119364738464355 Hits@1: 0.4385967254638672\n",
            "1.8501653671264648\n",
            "Epoch: 5 Loss: 3.5184848308563232, Val loss: 3.8163297176361084 Hits@1: 0.4706045985221863\n",
            "1.8501653671264648\n",
            "Epoch: 6 Loss: 3.194004535675049, Val loss: 3.5367190837860107 Hits@1: 0.4933681786060333\n",
            "1.8501653671264648\n",
            "Epoch: 7 Loss: 2.9439852237701416, Val loss: 3.333458185195923 Hits@1: 0.5085937976837158\n",
            "1.8501653671264648\n",
            "Epoch: 8 Loss: 2.7471814155578613, Val loss: 3.178215265274048 Hits@1: 0.520266056060791\n",
            "1.8501653671264648\n",
            "Epoch: 9 Loss: 2.585902214050293, Val loss: 3.063318967819214 Hits@1: 0.5325902700424194\n",
            "1.8501653671264648\n",
            "Epoch: 10 Loss: 2.449869394302368, Val loss: 2.9712040424346924 Hits@1: 0.5402628183364868\n",
            "1.8501653671264648\n",
            "Epoch: 11 Loss: 2.330811023712158, Val loss: 2.899299144744873 Hits@1: 0.5437784194946289\n",
            "1.8501653671264648\n",
            "Epoch: 12 Loss: 2.2270522117614746, Val loss: 2.8417282104492188 Hits@1: 0.5492166876792908\n",
            "1.8501653671264648\n",
            "Epoch: 13 Loss: 2.1342203617095947, Val loss: 2.793079137802124 Hits@1: 0.5530106425285339\n",
            "1.8501653671264648\n",
            "Epoch: 14 Loss: 2.0509610176086426, Val loss: 2.754880905151367 Hits@1: 0.5579179525375366\n",
            "1.8501653671264648\n",
            "Epoch: 15 Loss: 1.9744007587432861, Val loss: 2.7198312282562256 Hits@1: 0.5606983304023743\n",
            "1.8501653671264648\n",
            "Epoch: 16 Loss: 1.9039981365203857, Val loss: 2.696077585220337 Hits@1: 0.5630914568901062\n",
            "1.8501653671264648\n",
            "Epoch: 17 Loss: 1.8395110368728638, Val loss: 2.67318058013916 Hits@1: 0.5649974942207336\n",
            "1.8501653671264648\n",
            "Epoch: 18 Loss: 1.7801001071929932, Val loss: 2.6537954807281494 Hits@1: 0.5667915940284729\n",
            "1.8501653671264648\n",
            "Epoch: 19 Loss: 1.7233531475067139, Val loss: 2.6401686668395996 Hits@1: 0.5700182318687439\n",
            "1.8501653671264648\n"
          ]
        }
      ],
      "source": [
        "f = open(f'gowalla_rnn_stability_{coeff}.txt', 'w+')\n",
        "# for iteration in range(3):\n",
        "# torch.manual_seed(10 * iteration)\n",
        "torch.cuda.reset_peak_memory_stats(device)\n",
        "model = RNNTargetModel(num_classes)\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.97, last_epoch=-1)\n",
        "\n",
        "\n",
        "for i in range(20):\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    hits_1_scores = []\n",
        "\n",
        "    for user, train_input, train_time, train_label, train_time_label, test_input, test_time, test_label, \\\n",
        "    test_time_label, seq_len, train_repr, test_repr in user_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        comb_input = np.concatenate([np.expand_dims(train_input, axis=-1),\n",
        "                                                  np.expand_dims(train_time, axis=-1)], axis=2)\n",
        "        model_input = comb_input\n",
        "        model_output = train_label\n",
        "        rnn_input_emb = item_emb[model_input[:, :, 0]]\n",
        "        test_comb_input = np.concatenate([np.expand_dims(test_input, axis=-1),\n",
        "                                                  np.expand_dims(test_time, axis=-1)], axis=2)\n",
        "        test_model_input = test_comb_input\n",
        "        test_rnn_input_emb = item_emb[test_model_input[:, :, 0]]\n",
        "        probs = model(rnn_input_emb.cuda(), train_repr.cuda(), seq_len)\n",
        "        test_probs = model(test_rnn_input_emb.cuda(), test_repr.cuda(), seq_len)\n",
        "        pred = torch.argmax(probs, axis = 1)\n",
        "\n",
        "        one_hot = torch.zeros(len(probs), num_classes)\n",
        "        one_hot[torch.arange(len(one_hot)), model_output] = 1\n",
        "\n",
        "        test_one_hot = torch.zeros(len(test_probs), num_classes)\n",
        "        test_one_hot[torch.arange(len(test_one_hot)), test_label] = 1\n",
        "\n",
        "        loss = loss_fn(probs, one_hot.cuda())\n",
        "        val_loss = loss_fn(test_probs, test_one_hot.cuda())\n",
        "        losses.append(loss)\n",
        "        val_losses.append(val_loss)\n",
        "        hits_1_scores.append(top_k_accuracy_score(test_label, test_probs.cpu().detach().numpy(), k=1, labels = classes))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss)\n",
        "\n",
        "\n",
        "    mean_loss = torch.Tensor(losses).mean(axis=0)\n",
        "    mean_val_loss = torch.Tensor(val_losses).mean(axis = 0).item()\n",
        "    mean_hits = torch.Tensor(hits_1_scores).mean(axis=0).item()\n",
        "    print(f'Epoch: {i} Loss: {mean_loss.item()}, Val loss: {mean_val_loss} Hits@1: {mean_hits}')\n",
        "    print(torch.cuda.max_memory_allocated(0) / (1024 ** 3))\n",
        "    hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100 = rnn_target_test(model)\n",
        "    # f.write(f'Try: {iteration}, Seed: {10*iteration}\\n')\n",
        "    # write_to_file(f, hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100)\n",
        "    print_metrics(hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100)\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T20:06:00.428858Z",
          "iopub.status.busy": "2024-05-16T20:06:00.428035Z",
          "iopub.status.idle": "2024-05-16T20:06:00.471708Z",
          "shell.execute_reply": "2024-05-16T20:06:00.470570Z",
          "shell.execute_reply.started": "2024-05-16T20:06:00.428806Z"
        },
        "tags": [],
        "id": "wTdFqdMBqS4c",
        "outputId": "c3842af1-4b10-4c8b-81d2-9cd0be44c2ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29.3050537109375"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.mem_get_info()[0] / 1024 ** 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T20:06:00.474732Z",
          "iopub.status.busy": "2024-05-16T20:06:00.473769Z",
          "iopub.status.idle": "2024-05-16T20:06:00.508073Z",
          "shell.execute_reply": "2024-05-16T20:06:00.506901Z",
          "shell.execute_reply.started": "2024-05-16T20:06:00.474678Z"
        },
        "tags": [],
        "id": "6AHjhHhmqS4c",
        "outputId": "ddb7c4e5-2fb1-40cf-dcb0-787fe5b51ccb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.8501653671264648"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.max_memory_allocated(0) / (1024 ** 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Joint learning"
      ],
      "metadata": {
        "id": "WD2PWAzlr1Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphLinkPredictionModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(GraphLinkPredictionModel, self).__init__()\n",
        "\n",
        "    self.rnn = nn.RNN(128, 128, batch_first = True)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "    self.relu = nn.Tanh()\n",
        "    self.norm = nn.BatchNorm1d(128)\n",
        "    self.head_1 = nn.Sequential(nn.Linear(256, 1))\n",
        "    self.head_2 = nn.Linear(128, num_classes)\n",
        "    self.sigmoid= nn.Sigmoid()\n",
        "    self.graphconv = SAGEConv(128, 128)\n",
        "    self.graphconv2 = SAGEConv(128, 128)\n",
        "    self.prelu1 = nn.PReLU(128)\n",
        "    self.head_2 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x, seq_len, edge_index):\n",
        "    x, h = self.rnn(x)\n",
        "    hx = torch.zeros(x.shape[0], x.shape[2])\n",
        "    for i in range(hx.shape[0]):\n",
        "      hx[i] = x[i][seq_len[i] - 1]\n",
        "    hx = hx.to(device)\n",
        "    hx = self.norm(hx)\n",
        "    out_hx = hx\n",
        "    hx = self.graphconv(hx, edge_index)\n",
        "    hx = self.prelu1(hx)\n",
        "    hx = self.graphconv2(hx, edge_index)\n",
        "    hx = self.prelu1(hx)\n",
        "    hx = self.graphconv2(hx, edge_index)\n",
        "    x_src, x_dst = hx[edge_index[0]], hx[edge_index[1]]\n",
        "    x = torch.cat((x_src, x_dst), dim = 1)\n",
        "    x = self.head_1(x)\n",
        "    probs = self.head_2(hx)\n",
        "    return x, probs, hx"
      ],
      "metadata": {
        "id": "lDBU3nPusJ6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:10.911088Z",
          "iopub.status.busy": "2024-05-16T18:59:10.910306Z",
          "iopub.status.idle": "2024-05-16T18:59:10.937876Z",
          "shell.execute_reply": "2024-05-16T18:59:10.936685Z",
          "shell.execute_reply.started": "2024-05-16T18:59:10.911032Z"
        },
        "tags": [],
        "id": "yfqY0SfNsJ6S"
      },
      "outputs": [],
      "source": [
        "def joint_learning_test(model):\n",
        "  metrics_val = []\n",
        "  model.eval()\n",
        "  batch_num = 0\n",
        "  for batch in train_loader:\n",
        "      batch = batch.to(device)\n",
        "      batch_num += 1\n",
        "      _, test_probs, test_hx = model(batch.test_features, batch.seq_lens, batch.edge_label_index)\n",
        "      test_pred = torch.argmax(test_probs, axis = 1)\n",
        "      labels = batch.test_labels\n",
        "      test_one_hot = torch.zeros(len(test_probs), num_classes)\n",
        "      test_one_hot[torch.arange(len(test_one_hot)), labels] = 1\n",
        "\n",
        "      hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100,\\\n",
        "      ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100 = get_metrics_(test_probs, labels.cpu(), test_one_hot.cpu())\n",
        "      metrics_val.append([hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100])\n",
        "      if batch_num > 700:\n",
        "            break\n",
        "\n",
        "  mean = torch.Tensor(metrics_val).mean(axis=0)\n",
        "  test_hits1, test_hits5, test_hits10, test_hits20, test_hits50, test_hits100, test_map1, test_map5, test_map10, test_map20, test_map50, test_map100, \\\n",
        "  test_ndcg1, test_ndcg5,test_ndcg10, test_ndcg20, test_ndcg50, test_ndcg100 = mean\n",
        "\n",
        "  return test_hits1, test_hits5, test_hits10, test_hits20, test_hits50, test_hits100, test_map1, test_map5, test_map10, test_map20, test_map50, test_map100,\\\n",
        "  test_ndcg1, test_ndcg5,test_ndcg10, test_ndcg20, test_ndcg50, test_ndcg100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-16T18:59:21.449453Z",
          "iopub.status.busy": "2024-05-16T18:59:21.448252Z",
          "iopub.status.idle": "2024-05-16T19:43:53.825138Z"
        },
        "tags": [],
        "outputId": "24d07fea-2535-4b6a-87d4-5c74c6122073",
        "id": "kWfFWJHtsJ6S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 0.5328154563903809 Train Accuracy: 0.7150883078575134 Test Accuracy: 0.6756420135498047\n",
            "0.08614587783813477\n",
            "Epoch: 1 Loss: 0.467550128698349 Train Accuracy: 0.739663302898407 Test Accuracy: 0.6740946173667908\n",
            "0.09111881256103516\n",
            "Epoch: 2 Loss: 0.4365590810775757 Train Accuracy: 0.755257248878479 Test Accuracy: 0.6690285801887512\n",
            "0.09484338760375977\n",
            "Epoch: 3 Loss: 0.4140571057796478 Train Accuracy: 0.7670415639877319 Test Accuracy: 0.6642501354217529\n",
            "0.09961557388305664\n",
            "Epoch: 4 Loss: 0.3987140953540802 Train Accuracy: 0.7761774659156799 Test Accuracy: 0.6588885188102722\n",
            "0.10285043716430664\n",
            "Epoch: 5 Loss: 0.38458681106567383 Train Accuracy: 0.7837252616882324 Test Accuracy: 0.6538312435150146\n",
            "0.10593891143798828\n",
            "Epoch: 6 Loss: 0.3747740685939789 Train Accuracy: 0.7901202440261841 Test Accuracy: 0.6488096714019775\n",
            "0.11064863204956055\n",
            "Epoch: 7 Loss: 0.36430999636650085 Train Accuracy: 0.7956680059432983 Test Accuracy: 0.644772469997406\n",
            "0.11440610885620117\n",
            "Epoch: 8 Loss: 0.35635411739349365 Train Accuracy: 0.8005428314208984 Test Accuracy: 0.6410403847694397\n",
            "0.11897420883178711\n",
            "Epoch: 9 Loss: 0.3487343192100525 Train Accuracy: 0.8049153089523315 Test Accuracy: 0.6376956105232239\n",
            "0.39248037338256836\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.reset_peak_memory_stats(device)\n",
        "next_loss_fn = nn.CrossEntropyLoss()\n",
        "model = GraphLinkPredictionModel()\n",
        "link_loss_fn = nn.BCEWithLogitsLoss()\n",
        "accuracy = BinaryAccuracy().to(device)\n",
        "model.to(device)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.97, last_epoch=-1)\n",
        "\n",
        "train_user_representations = {}\n",
        "test_user_representations = {}\n",
        "num_epochs = 10\n",
        "accuracies = []\n",
        "test_accuracies = []\n",
        "for i in range(num_epochs):\n",
        "  losses = []\n",
        "  hits_1_scores = []\n",
        "  batch_num = 0\n",
        "  for batch in train_loader:\n",
        "      batch_num += 1\n",
        "      optimizer.zero_grad()\n",
        "      batch = batch.to(device)\n",
        "\n",
        "      link_probs, next_probs, hx = model(batch.x, batch.seq_lens, batch.edge_label_index)\n",
        "      test_link_probs, test_next_probs, test_hx = model(batch.test_features, batch.seq_lens, batch.edge_label_index)\n",
        "      link_probs = link_probs.squeeze()\n",
        "      test_link_probs = test_link_probs.squeeze()\n",
        "\n",
        "      one_hot = torch.zeros(len(next_probs), num_classes)\n",
        "      one_hot[torch.arange(len(one_hot)), batch.train_labels] = 1\n",
        "      test_one_hot = torch.zeros(len(test_next_probs), num_classes)\n",
        "      test_one_hot[torch.arange(len(test_one_hot)), batch.test_labels] = 1\n",
        "      hits_1_scores.append(top_k_accuracy_score(batch.test_labels, test_next_probs.cpu().detach().numpy(), k=1, labels = classes))\n",
        "\n",
        "      gt = batch.edge_label\n",
        "      link_loss = link_loss_fn(link_probs, gt)\n",
        "      accuracies.append(accuracy(link_probs, gt))\n",
        "      test_accuracies.append(accuracy(test_link_probs, gt))\n",
        "      next_loss = next_loss_fn(next_probs, one_hot)\n",
        "      loss = 1 * link_loss\n",
        "      loss = next_loss\n",
        "      losses.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if i == num_epochs - 1:\n",
        "        index = 0\n",
        "        for u in batch.user_ids:\n",
        "          user = u.item()\n",
        "          if user not in train_user_representations.keys():\n",
        "            train_user_representations[user] = (hx[index].detach(), batch.train_labels[index])\n",
        "          if user not in test_user_representations.keys():\n",
        "            test_user_representations[user] = (test_hx[index].detach(), batch.test_labels[index])\n",
        "          index += 1\n",
        "\n",
        "  mean_loss = torch.Tensor(losses).mean(axis=0)\n",
        "  mean_hits = torch.Tensor(hits_1_scores).mean(axis=0).item()\n",
        "  mean_acc = torch.Tensor(accuracies).mean(axis=0).item()\n",
        "  mean_test_acc = torch.Tensor(test_accuracies).mean(axis=0).item()\n",
        "  print(f'Epoch: {i} Loss: {mean_loss.item()}, Test hits@1: {mean_hits}')\n",
        "  print(f'Epoch: {i} Loss: {mean_loss.item()} Train Accuracy: {mean_acc} Test Accuracy: {mean_test_acc}')\n",
        "  print(torch.cuda.max_memory_allocated(0) / (1024 ** 3))\n",
        "hits1, hits5, hits10, hits20, hits50, hits100, map1,map5, map10, map20, map50, map100, \\\n",
        "ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100 = joint_learning_test(model)\n",
        "print_metrics(hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-13T21:04:04.186327Z",
          "iopub.status.busy": "2024-05-13T21:04:04.185215Z",
          "iopub.status.idle": "2024-05-13T21:11:21.387770Z",
          "shell.execute_reply": "2024-05-13T21:11:21.385816Z",
          "shell.execute_reply.started": "2024-05-13T21:04:04.186274Z"
        },
        "tags": [],
        "outputId": "f6a63ff4-73c3-4cee-b927-84191b1e3874",
        "id": "rewGuIMxsJ6T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "hits@1: 0.809080, hits@5: 0.938266, hits@10: 0.954177, hits@20: 0.972476\n",
            "hits@50: 0.990620, hits@100: 0.997281\n",
            "map@1: 0.809080, map@5: 0.862547, map@10: 0.864691, map@20: 0.866001\n",
            "map@50: 0.866599, map@100: 0.866699\n",
            "ndcg@1: 0.809080, ndcg@5: 0.881698, ndcg@10: 0.886863, ndcg@20: 0.891541\n",
            "ndcg@50: 0.895180, ndcg@100: 0.896273\n"
          ]
        }
      ],
      "source": [
        "hits1, hits5, hits10, hits20, hits50, hits100, map1,map5, map10, map20, map50, map100, \\\n",
        "ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100 = joint_learning_test(model)\n",
        "print_metrics(hits1, hits5, hits10, hits20, hits50, hits100, map1, map5, map10, map20, map50, map100, ndcg1, ndcg5, ndcg10, ndcg20, ndcg50, ndcg100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9TBCg25L2eNY"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DataSphere Kernel",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}